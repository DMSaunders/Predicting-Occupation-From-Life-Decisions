{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "import src.features.feature_cleaning as feature_cleaning\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "#sklearn models\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#sklearn other\n",
    "import graphviz \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, log_loss\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, fieldofdegree_df, SOCP_labels, schl_labels, major_majors, NAICSP_labels_df, MAJ_NAICSP_labels_df = feature_cleaning.load_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/features/feature_cleaning.py:81: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  SOCPdf = df.dropna(axis='index', subset=['SOCP'])[df.SOCP != '999920']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of employed people: 218454\n",
      "Percent employed people: 0.5785711448056677\n",
      "Number of young employed people: 77406\n",
      "Percent young employed people(out of all PUMS): 0.20500827650135733\n",
      "Number of emp cats: 23\n",
      "Number of degree fields present (max 173): 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "../src/features/feature_cleaning.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  edu_df['SCHL_ord'] = edu_df.SCHL.astype(int)\n",
      "../src/features/feature_cleaning.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "../src/features/feature_cleaning.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  #make major majors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dummies:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 77406 entries, 0 to 77405\n",
      "Data columns (total 14 columns):\n",
      "SERIALNO            77406 non-null int64\n",
      "SOCP                77406 non-null object\n",
      "MAJ_SOCP            77406 non-null object\n",
      "MAJ_SOCP_labels     77406 non-null object\n",
      "MAJ_SOCP_15         77406 non-null int64\n",
      "FOD1P               77406 non-null object\n",
      "FOD2P               77406 non-null object\n",
      "FOD1P_labels        77406 non-null object\n",
      "FOD2P_labels        77406 non-null object\n",
      "SCHL                77406 non-null object\n",
      "SCHL_labels         77406 non-null object\n",
      "SCHL_ord            77406 non-null int64\n",
      "FOD1P_MAJ           77406 non-null int64\n",
      "FOD1P_MAJ_labels    77406 non-null object\n",
      "dtypes: int64(4), object(10)\n",
      "memory usage: 53.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "youngemp_df = feature_cleaning.clean_that_target(df, SOCP_labels)\n",
    "youngemp_df = feature_cleaning.single_occ_target(youngemp_df)\n",
    "edu_df = feature_cleaning.create_edu_df(youngemp_df, fieldofdegree_df, schl_labels, major_majors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>SOCP</th>\n",
       "      <th>MAJ_SOCP</th>\n",
       "      <th>MAJ_SOCP_labels</th>\n",
       "      <th>MAJ_SOCP_15</th>\n",
       "      <th>FOD1P</th>\n",
       "      <th>FOD2P</th>\n",
       "      <th>FOD1P_labels</th>\n",
       "      <th>FOD2P_labels</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCHL_labels</th>\n",
       "      <th>SCHL_ord</th>\n",
       "      <th>FOD1P_MAJ</th>\n",
       "      <th>FOD1P_MAJ_labels</th>\n",
       "      <th>FOD1P_MAJ__Agriculture, agriculture operations, and related sciences</th>\n",
       "      <th>FOD1P_MAJ__Architecture and related services</th>\n",
       "      <th>FOD1P_MAJ__Area, ethnic, cultural, gender, and group studies</th>\n",
       "      <th>FOD1P_MAJ__Biological and biomedical sciences</th>\n",
       "      <th>FOD1P_MAJ__Business, management, marketing, and related support services</th>\n",
       "      <th>FOD1P_MAJ__Communication, journalism, and related programs</th>\n",
       "      <th>FOD1P_MAJ__Communications technologies/technicians and support services</th>\n",
       "      <th>FOD1P_MAJ__Computer and information sciences and support services</th>\n",
       "      <th>FOD1P_MAJ__Construction trades</th>\n",
       "      <th>FOD1P_MAJ__Education</th>\n",
       "      <th>FOD1P_MAJ__Engineering</th>\n",
       "      <th>FOD1P_MAJ__Engineering technologies and engineering-related fields</th>\n",
       "      <th>FOD1P_MAJ__English language and literature/letters</th>\n",
       "      <th>FOD1P_MAJ__Family and consumer sciences/human sciences</th>\n",
       "      <th>FOD1P_MAJ__Foreign languages, literatures, and linguistics</th>\n",
       "      <th>FOD1P_MAJ__Health professions and related programs</th>\n",
       "      <th>FOD1P_MAJ__History</th>\n",
       "      <th>FOD1P_MAJ__Homeland security, law enforcement, firefighting and related protective services</th>\n",
       "      <th>FOD1P_MAJ__Legal professions and studies</th>\n",
       "      <th>FOD1P_MAJ__Liberal arts and sciences, general studies and humanities</th>\n",
       "      <th>FOD1P_MAJ__Library science</th>\n",
       "      <th>FOD1P_MAJ__Mathematics and statistics</th>\n",
       "      <th>FOD1P_MAJ__Mechanic and repair technologies/technicians</th>\n",
       "      <th>FOD1P_MAJ__Military science, leadership and operational art</th>\n",
       "      <th>FOD1P_MAJ__Multi/interdisciplinary studies</th>\n",
       "      <th>FOD1P_MAJ__Natural resources and conservation</th>\n",
       "      <th>FOD1P_MAJ__No major</th>\n",
       "      <th>FOD1P_MAJ__Parks, recreation, leisure, and fitness studies</th>\n",
       "      <th>FOD1P_MAJ__Personal and culinary services</th>\n",
       "      <th>FOD1P_MAJ__Philosophy and religious studies</th>\n",
       "      <th>FOD1P_MAJ__Physical sciences</th>\n",
       "      <th>FOD1P_MAJ__Psychology</th>\n",
       "      <th>FOD1P_MAJ__Public administration and social service professions</th>\n",
       "      <th>FOD1P_MAJ__Science technologies/technicians</th>\n",
       "      <th>FOD1P_MAJ__Social sciences</th>\n",
       "      <th>FOD1P_MAJ__Theology and religious vocations</th>\n",
       "      <th>FOD1P_MAJ__Transportation and materials moving</th>\n",
       "      <th>FOD1P_MAJ__Visual and performing arts</th>\n",
       "      <th>FOD1P__Accounting</th>\n",
       "      <th>FOD1P__Actuarial Science</th>\n",
       "      <th>FOD1P__Advertising And Public Relations</th>\n",
       "      <th>FOD1P__Aerospace Engineering</th>\n",
       "      <th>FOD1P__Agricultural Economics</th>\n",
       "      <th>FOD1P__Agriculture Production And Management</th>\n",
       "      <th>FOD1P__Animal Sciences</th>\n",
       "      <th>FOD1P__Anthropology And Archeology</th>\n",
       "      <th>FOD1P__Applied Mathematics</th>\n",
       "      <th>FOD1P__Architectural Engineering</th>\n",
       "      <th>FOD1P__Architecture</th>\n",
       "      <th>FOD1P__Area Ethnic And Civilization Studies</th>\n",
       "      <th>FOD1P__Art And Music Education</th>\n",
       "      <th>FOD1P__Art History And Criticism</th>\n",
       "      <th>FOD1P__Astronomy And Astrophysics</th>\n",
       "      <th>FOD1P__Atmospheric Sciences And Meteorology</th>\n",
       "      <th>FOD1P__Biochemical Sciences</th>\n",
       "      <th>FOD1P__Biological Engineering</th>\n",
       "      <th>FOD1P__Biology</th>\n",
       "      <th>FOD1P__Biomedical Engineering</th>\n",
       "      <th>FOD1P__Botany</th>\n",
       "      <th>FOD1P__Business Economics</th>\n",
       "      <th>FOD1P__Business Management And Administration</th>\n",
       "      <th>FOD1P__Chemical Engineering</th>\n",
       "      <th>FOD1P__Chemistry</th>\n",
       "      <th>FOD1P__Civil Engineering</th>\n",
       "      <th>FOD1P__Clinical Psychology</th>\n",
       "      <th>FOD1P__Cognitive Science And Biopsychology</th>\n",
       "      <th>FOD1P__Commercial Art And Graphic Design</th>\n",
       "      <th>FOD1P__Communication Disorders Sciences And Services</th>\n",
       "      <th>FOD1P__Communication Technologies</th>\n",
       "      <th>FOD1P__Communications</th>\n",
       "      <th>FOD1P__Community And Public Health</th>\n",
       "      <th>FOD1P__Composition And Rhetoric</th>\n",
       "      <th>FOD1P__Computer Administration Management And Security</th>\n",
       "      <th>FOD1P__Computer And Information Systems</th>\n",
       "      <th>FOD1P__Computer Engineering</th>\n",
       "      <th>FOD1P__Computer Networking And Telecommunications</th>\n",
       "      <th>FOD1P__Computer Programming And Data Processing</th>\n",
       "      <th>FOD1P__Computer Science</th>\n",
       "      <th>FOD1P__Construction Services</th>\n",
       "      <th>FOD1P__Cosmetology Services And Culinary Arts</th>\n",
       "      <th>FOD1P__Counseling Psychology</th>\n",
       "      <th>FOD1P__Court Reporting</th>\n",
       "      <th>FOD1P__Criminal Justice And Fire Protection</th>\n",
       "      <th>FOD1P__Criminology</th>\n",
       "      <th>FOD1P__Drama And Theater Arts</th>\n",
       "      <th>FOD1P__Early Childhood Education</th>\n",
       "      <th>FOD1P__Ecology</th>\n",
       "      <th>FOD1P__Economics</th>\n",
       "      <th>FOD1P__Educational Administration And Supervision</th>\n",
       "      <th>FOD1P__Educational Psychology</th>\n",
       "      <th>FOD1P__Electrical Engineering</th>\n",
       "      <th>FOD1P__Electrical Engineering Technology</th>\n",
       "      <th>FOD1P__Electrical, Mechanical, And Precision Technologies And Production</th>\n",
       "      <th>FOD1P__Elementary Education</th>\n",
       "      <th>FOD1P__Engineering And Industrial Management</th>\n",
       "      <th>FOD1P__Engineering Mechanics Physics And Science</th>\n",
       "      <th>FOD1P__Engineering Technologies</th>\n",
       "      <th>FOD1P__English Language And Literature</th>\n",
       "      <th>FOD1P__Environmental Engineering</th>\n",
       "      <th>FOD1P__Environmental Science</th>\n",
       "      <th>FOD1P__Family And Consumer Sciences</th>\n",
       "      <th>FOD1P__Film Video And Photographic Arts</th>\n",
       "      <th>FOD1P__Finance</th>\n",
       "      <th>FOD1P__Fine Arts</th>\n",
       "      <th>FOD1P__Food Science</th>\n",
       "      <th>FOD1P__Forestry</th>\n",
       "      <th>FOD1P__French German Latin And Other Common Foreign Language Studies</th>\n",
       "      <th>FOD1P__General Agriculture</th>\n",
       "      <th>FOD1P__General Business</th>\n",
       "      <th>FOD1P__General Education</th>\n",
       "      <th>FOD1P__General Engineering</th>\n",
       "      <th>FOD1P__General Medical And Health Services</th>\n",
       "      <th>FOD1P__General Social Sciences</th>\n",
       "      <th>FOD1P__Genetics</th>\n",
       "      <th>FOD1P__Geography</th>\n",
       "      <th>FOD1P__Geological And Geophysical Engineering</th>\n",
       "      <th>FOD1P__Geology And Earth Science</th>\n",
       "      <th>FOD1P__Geosciences</th>\n",
       "      <th>FOD1P__Health And Medical Administrative Services</th>\n",
       "      <th>FOD1P__Health And Medical Preparatory Programs</th>\n",
       "      <th>FOD1P__History</th>\n",
       "      <th>FOD1P__Hospitality Management</th>\n",
       "      <th>FOD1P__Human Resources And Personnel Management</th>\n",
       "      <th>FOD1P__Human Services And Community Organization</th>\n",
       "      <th>FOD1P__Humanities</th>\n",
       "      <th>FOD1P__Industrial And Manufacturing Engineering</th>\n",
       "      <th>FOD1P__Industrial And Organizational Psychology</th>\n",
       "      <th>FOD1P__Industrial Production Technologies</th>\n",
       "      <th>FOD1P__Information Sciences</th>\n",
       "      <th>FOD1P__Intercultural And International Studies</th>\n",
       "      <th>FOD1P__Interdisciplinary Social Sciences</th>\n",
       "      <th>FOD1P__International Business</th>\n",
       "      <th>FOD1P__International Relations</th>\n",
       "      <th>FOD1P__Journalism</th>\n",
       "      <th>FOD1P__Language And Drama Education</th>\n",
       "      <th>FOD1P__Liberal Arts</th>\n",
       "      <th>FOD1P__Library Science</th>\n",
       "      <th>FOD1P__Linguistics And Comparative Language And Literature</th>\n",
       "      <th>FOD1P__Management Information Systems And Statistics</th>\n",
       "      <th>FOD1P__Marketing And Marketing Research</th>\n",
       "      <th>FOD1P__Mass Media</th>\n",
       "      <th>FOD1P__Materials Engineering And Materials Science</th>\n",
       "      <th>FOD1P__Materials Science</th>\n",
       "      <th>FOD1P__Mathematics</th>\n",
       "      <th>FOD1P__Mathematics And Computer Science</th>\n",
       "      <th>FOD1P__Mathematics Teacher Education</th>\n",
       "      <th>FOD1P__Mechanical Engineering</th>\n",
       "      <th>FOD1P__Mechanical Engineering Related Technologies</th>\n",
       "      <th>FOD1P__Medical Assisting Services</th>\n",
       "      <th>FOD1P__Medical Technologies Technicians</th>\n",
       "      <th>FOD1P__Metallurgical Engineering</th>\n",
       "      <th>FOD1P__Microbiology</th>\n",
       "      <th>FOD1P__Military Technologies</th>\n",
       "      <th>FOD1P__Mining And Mineral Engineering</th>\n",
       "      <th>FOD1P__Miscellaneous Agriculture</th>\n",
       "      <th>FOD1P__Miscellaneous Biology</th>\n",
       "      <th>FOD1P__Miscellaneous Business &amp; Medical Administration</th>\n",
       "      <th>FOD1P__Miscellaneous Education</th>\n",
       "      <th>FOD1P__Miscellaneous Engineering</th>\n",
       "      <th>FOD1P__Miscellaneous Engineering Technologies</th>\n",
       "      <th>FOD1P__Miscellaneous Fine Arts</th>\n",
       "      <th>FOD1P__Miscellaneous Health Medical Professions</th>\n",
       "      <th>FOD1P__Miscellaneous Psychology</th>\n",
       "      <th>FOD1P__Miscellaneous Social Sciences</th>\n",
       "      <th>FOD1P__Molecular Biology</th>\n",
       "      <th>FOD1P__Multi-Disciplinary Or General Science</th>\n",
       "      <th>FOD1P__Multi/Interdisciplinary Studies</th>\n",
       "      <th>FOD1P__Music</th>\n",
       "      <th>FOD1P__Natural Resources Management</th>\n",
       "      <th>FOD1P__Naval Architecture And Marine Engineering</th>\n",
       "      <th>FOD1P__Neuroscience</th>\n",
       "      <th>FOD1P__No major</th>\n",
       "      <th>FOD1P__Nuclear Engineering</th>\n",
       "      <th>FOD1P__Nuclear, Industrial Radiology, And Biological Technologies</th>\n",
       "      <th>FOD1P__Nursing</th>\n",
       "      <th>FOD1P__Nutrition Sciences</th>\n",
       "      <th>FOD1P__Oceanography</th>\n",
       "      <th>FOD1P__Operations Logistics And E-Commerce</th>\n",
       "      <th>FOD1P__Other Foreign Languages</th>\n",
       "      <th>FOD1P__Petroleum Engineering</th>\n",
       "      <th>FOD1P__Pharmacology</th>\n",
       "      <th>FOD1P__Pharmacy Pharmaceutical Sciences And Administration</th>\n",
       "      <th>FOD1P__Philosophy And Religious Studies</th>\n",
       "      <th>FOD1P__Physical And Health Education Teaching</th>\n",
       "      <th>FOD1P__Physical Fitness Parks Recreation And Leisure</th>\n",
       "      <th>FOD1P__Physical Sciences</th>\n",
       "      <th>FOD1P__Physics</th>\n",
       "      <th>FOD1P__Physiology</th>\n",
       "      <th>FOD1P__Plant Science And Agronomy</th>\n",
       "      <th>FOD1P__Political Science And Government</th>\n",
       "      <th>FOD1P__Pre-Law And Legal Studies</th>\n",
       "      <th>FOD1P__Psychology</th>\n",
       "      <th>FOD1P__Public Administration</th>\n",
       "      <th>FOD1P__Public Policy</th>\n",
       "      <th>FOD1P__School Student Counseling</th>\n",
       "      <th>FOD1P__Science And Computer Teacher Education</th>\n",
       "      <th>FOD1P__Secondary Teacher Education</th>\n",
       "      <th>FOD1P__Social Psychology</th>\n",
       "      <th>FOD1P__Social Science Or History Teacher Education</th>\n",
       "      <th>FOD1P__Social Work</th>\n",
       "      <th>FOD1P__Sociology</th>\n",
       "      <th>FOD1P__Soil Science</th>\n",
       "      <th>FOD1P__Special Needs Education</th>\n",
       "      <th>FOD1P__Statistics And Decision Science</th>\n",
       "      <th>FOD1P__Studio Arts</th>\n",
       "      <th>FOD1P__Teacher Education: Multiple Levels</th>\n",
       "      <th>FOD1P__Theology And Religious Vocations</th>\n",
       "      <th>FOD1P__Transportation Sciences And Technologies</th>\n",
       "      <th>FOD1P__Treatment Therapy Professions</th>\n",
       "      <th>FOD1P__United States History</th>\n",
       "      <th>FOD1P__Visual And Performing Arts</th>\n",
       "      <th>FOD1P__Zoology</th>\n",
       "      <th>FOD2P__Accounting</th>\n",
       "      <th>FOD2P__Advertising And Public Relations</th>\n",
       "      <th>FOD2P__Aerospace Engineering</th>\n",
       "      <th>FOD2P__Agriculture Production And Management</th>\n",
       "      <th>FOD2P__Animal Sciences</th>\n",
       "      <th>FOD2P__Anthropology And Archeology</th>\n",
       "      <th>FOD2P__Applied Mathematics</th>\n",
       "      <th>FOD2P__Architecture</th>\n",
       "      <th>FOD2P__Area Ethnic And Civilization Studies</th>\n",
       "      <th>FOD2P__Art And Music Education</th>\n",
       "      <th>FOD2P__Art History And Criticism</th>\n",
       "      <th>FOD2P__Astronomy And Astrophysics</th>\n",
       "      <th>FOD2P__Atmospheric Sciences And Meteorology</th>\n",
       "      <th>FOD2P__Biochemical Sciences</th>\n",
       "      <th>FOD2P__Biological Engineering</th>\n",
       "      <th>FOD2P__Biology</th>\n",
       "      <th>FOD2P__Biomedical Engineering</th>\n",
       "      <th>FOD2P__Business Economics</th>\n",
       "      <th>FOD2P__Business Management And Administration</th>\n",
       "      <th>FOD2P__Chemistry</th>\n",
       "      <th>FOD2P__Civil Engineering</th>\n",
       "      <th>FOD2P__Clinical Psychology</th>\n",
       "      <th>FOD2P__Cognitive Science And Biopsychology</th>\n",
       "      <th>FOD2P__Commercial Art And Graphic Design</th>\n",
       "      <th>FOD2P__Communication Disorders Sciences And Services</th>\n",
       "      <th>FOD2P__Communication Technologies</th>\n",
       "      <th>FOD2P__Communications</th>\n",
       "      <th>FOD2P__Community And Public Health</th>\n",
       "      <th>FOD2P__Composition And Rhetoric</th>\n",
       "      <th>FOD2P__Computer Administration Management And Security</th>\n",
       "      <th>FOD2P__Computer And Information Systems</th>\n",
       "      <th>FOD2P__Computer Engineering</th>\n",
       "      <th>FOD2P__Computer Networking And Telecommunications</th>\n",
       "      <th>FOD2P__Computer Programming And Data Processing</th>\n",
       "      <th>FOD2P__Computer Science</th>\n",
       "      <th>FOD2P__Cosmetology Services And Culinary Arts</th>\n",
       "      <th>FOD2P__Counseling Psychology</th>\n",
       "      <th>FOD2P__Criminal Justice And Fire Protection</th>\n",
       "      <th>FOD2P__Criminology</th>\n",
       "      <th>FOD2P__Drama And Theater Arts</th>\n",
       "      <th>FOD2P__Early Childhood Education</th>\n",
       "      <th>FOD2P__Ecology</th>\n",
       "      <th>FOD2P__Economics</th>\n",
       "      <th>FOD2P__Educational Administration And Supervision</th>\n",
       "      <th>FOD2P__Educational Psychology</th>\n",
       "      <th>FOD2P__Electrical Engineering</th>\n",
       "      <th>FOD2P__Electrical Engineering Technology</th>\n",
       "      <th>FOD2P__Electrical, Mechanical, And Precision Technologies And Production</th>\n",
       "      <th>FOD2P__Elementary Education</th>\n",
       "      <th>FOD2P__Engineering And Industrial Management</th>\n",
       "      <th>FOD2P__Engineering Mechanics Physics And Science</th>\n",
       "      <th>FOD2P__Engineering Technologies</th>\n",
       "      <th>FOD2P__English Language And Literature</th>\n",
       "      <th>FOD2P__Environmental Engineering</th>\n",
       "      <th>FOD2P__Environmental Science</th>\n",
       "      <th>FOD2P__Family And Consumer Sciences</th>\n",
       "      <th>FOD2P__Film Video And Photographic Arts</th>\n",
       "      <th>FOD2P__Finance</th>\n",
       "      <th>FOD2P__Fine Arts</th>\n",
       "      <th>FOD2P__Food Science</th>\n",
       "      <th>FOD2P__Forestry</th>\n",
       "      <th>FOD2P__French German Latin And Other Common Foreign Language Studies</th>\n",
       "      <th>FOD2P__General Business</th>\n",
       "      <th>FOD2P__General Education</th>\n",
       "      <th>FOD2P__General Engineering</th>\n",
       "      <th>FOD2P__General Medical And Health Services</th>\n",
       "      <th>FOD2P__General Social Sciences</th>\n",
       "      <th>FOD2P__Genetics</th>\n",
       "      <th>FOD2P__Geography</th>\n",
       "      <th>FOD2P__Geology And Earth Science</th>\n",
       "      <th>FOD2P__Geosciences</th>\n",
       "      <th>FOD2P__Health And Medical Administrative Services</th>\n",
       "      <th>FOD2P__Health And Medical Preparatory Programs</th>\n",
       "      <th>FOD2P__History</th>\n",
       "      <th>FOD2P__Hospitality Management</th>\n",
       "      <th>FOD2P__Human Resources And Personnel Management</th>\n",
       "      <th>FOD2P__Human Services And Community Organization</th>\n",
       "      <th>FOD2P__Humanities</th>\n",
       "      <th>FOD2P__Industrial And Manufacturing Engineering</th>\n",
       "      <th>FOD2P__Industrial And Organizational Psychology</th>\n",
       "      <th>FOD2P__Industrial Production Technologies</th>\n",
       "      <th>FOD2P__Information Sciences</th>\n",
       "      <th>FOD2P__Intercultural And International Studies</th>\n",
       "      <th>FOD2P__Interdisciplinary Social Sciences</th>\n",
       "      <th>FOD2P__International Business</th>\n",
       "      <th>FOD2P__International Relations</th>\n",
       "      <th>FOD2P__Journalism</th>\n",
       "      <th>FOD2P__Language And Drama Education</th>\n",
       "      <th>FOD2P__Liberal Arts</th>\n",
       "      <th>FOD2P__Library Science</th>\n",
       "      <th>FOD2P__Linguistics And Comparative Language And Literature</th>\n",
       "      <th>FOD2P__Management Information Systems And Statistics</th>\n",
       "      <th>FOD2P__Marketing And Marketing Research</th>\n",
       "      <th>FOD2P__Mass Media</th>\n",
       "      <th>FOD2P__Materials Engineering And Materials Science</th>\n",
       "      <th>FOD2P__Materials Science</th>\n",
       "      <th>FOD2P__Mathematics</th>\n",
       "      <th>FOD2P__Mathematics And Computer Science</th>\n",
       "      <th>FOD2P__Mechanical Engineering</th>\n",
       "      <th>FOD2P__Medical Assisting Services</th>\n",
       "      <th>FOD2P__Medical Technologies Technicians</th>\n",
       "      <th>FOD2P__Metallurgical Engineering</th>\n",
       "      <th>FOD2P__Microbiology</th>\n",
       "      <th>FOD2P__Miscellaneous Biology</th>\n",
       "      <th>FOD2P__Miscellaneous Business &amp; Medical Administration</th>\n",
       "      <th>FOD2P__Miscellaneous Education</th>\n",
       "      <th>FOD2P__Miscellaneous Engineering</th>\n",
       "      <th>FOD2P__Miscellaneous Engineering Technologies</th>\n",
       "      <th>FOD2P__Miscellaneous Fine Arts</th>\n",
       "      <th>FOD2P__Miscellaneous Health Medical Professions</th>\n",
       "      <th>FOD2P__Miscellaneous Psychology</th>\n",
       "      <th>FOD2P__Miscellaneous Social Sciences</th>\n",
       "      <th>FOD2P__Molecular Biology</th>\n",
       "      <th>FOD2P__Multi-Disciplinary Or General Science</th>\n",
       "      <th>FOD2P__Multi/Interdisciplinary Studies</th>\n",
       "      <th>FOD2P__Music</th>\n",
       "      <th>FOD2P__Natural Resources Management</th>\n",
       "      <th>FOD2P__Neuroscience</th>\n",
       "      <th>FOD2P__No major</th>\n",
       "      <th>FOD2P__Nursing</th>\n",
       "      <th>FOD2P__Nutrition Sciences</th>\n",
       "      <th>FOD2P__Oceanography</th>\n",
       "      <th>FOD2P__Operations Logistics And E-Commerce</th>\n",
       "      <th>FOD2P__Other Foreign Languages</th>\n",
       "      <th>FOD2P__Pharmacy Pharmaceutical Sciences And Administration</th>\n",
       "      <th>FOD2P__Philosophy And Religious Studies</th>\n",
       "      <th>FOD2P__Physical And Health Education Teaching</th>\n",
       "      <th>FOD2P__Physical Fitness Parks Recreation And Leisure</th>\n",
       "      <th>FOD2P__Physical Sciences</th>\n",
       "      <th>FOD2P__Physics</th>\n",
       "      <th>FOD2P__Physiology</th>\n",
       "      <th>FOD2P__Plant Science And Agronomy</th>\n",
       "      <th>FOD2P__Political Science And Government</th>\n",
       "      <th>FOD2P__Pre-Law And Legal Studies</th>\n",
       "      <th>FOD2P__Psychology</th>\n",
       "      <th>FOD2P__Public Administration</th>\n",
       "      <th>FOD2P__Public Policy</th>\n",
       "      <th>FOD2P__Science And Computer Teacher Education</th>\n",
       "      <th>FOD2P__Secondary Teacher Education</th>\n",
       "      <th>FOD2P__Social Science Or History Teacher Education</th>\n",
       "      <th>FOD2P__Social Work</th>\n",
       "      <th>FOD2P__Sociology</th>\n",
       "      <th>FOD2P__Soil Science</th>\n",
       "      <th>FOD2P__Special Needs Education</th>\n",
       "      <th>FOD2P__Statistics And Decision Science</th>\n",
       "      <th>FOD2P__Studio Arts</th>\n",
       "      <th>FOD2P__Theology And Religious Vocations</th>\n",
       "      <th>FOD2P__Treatment Therapy Professions</th>\n",
       "      <th>FOD2P__United States History</th>\n",
       "      <th>FOD2P__Visual And Performing Arts</th>\n",
       "      <th>FOD2P__Zoology</th>\n",
       "      <th>SCHL__1 or more years of college credit, no degree</th>\n",
       "      <th>SCHL__12th grade - no diploma</th>\n",
       "      <th>SCHL__Associate's degree</th>\n",
       "      <th>SCHL__Bachelor's degree</th>\n",
       "      <th>SCHL__Doctorate degree</th>\n",
       "      <th>SCHL__GED or alternative credential</th>\n",
       "      <th>SCHL__Grade 1</th>\n",
       "      <th>SCHL__Grade 10</th>\n",
       "      <th>SCHL__Grade 11</th>\n",
       "      <th>SCHL__Grade 2</th>\n",
       "      <th>SCHL__Grade 3</th>\n",
       "      <th>SCHL__Grade 4</th>\n",
       "      <th>SCHL__Grade 5</th>\n",
       "      <th>SCHL__Grade 6</th>\n",
       "      <th>SCHL__Grade 7</th>\n",
       "      <th>SCHL__Grade 8</th>\n",
       "      <th>SCHL__Grade 9</th>\n",
       "      <th>SCHL__Kindergarten</th>\n",
       "      <th>SCHL__Master's degree</th>\n",
       "      <th>SCHL__No schooling completed</th>\n",
       "      <th>SCHL__Nursery school, preschool</th>\n",
       "      <th>SCHL__Professional degree beyond a bachelor's degree</th>\n",
       "      <th>SCHL__Regular high school diploma</th>\n",
       "      <th>SCHL__Some college, but less than 1 year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40527</th>\n",
       "      <td>2017000772957</td>\n",
       "      <td>119021</td>\n",
       "      <td>11</td>\n",
       "      <td>Management</td>\n",
       "      <td>0</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>No major</td>\n",
       "      <td>No major</td>\n",
       "      <td>17</td>\n",
       "      <td>GED or alternative credential</td>\n",
       "      <td>17</td>\n",
       "      <td>99</td>\n",
       "      <td>No major</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31850</th>\n",
       "      <td>2017000607027</td>\n",
       "      <td>131161</td>\n",
       "      <td>13</td>\n",
       "      <td>Business and Financial Operations</td>\n",
       "      <td>0</td>\n",
       "      <td>5501</td>\n",
       "      <td>9999</td>\n",
       "      <td>Economics</td>\n",
       "      <td>No major</td>\n",
       "      <td>21</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>21</td>\n",
       "      <td>55</td>\n",
       "      <td>Social sciences</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76207</th>\n",
       "      <td>2017001499692</td>\n",
       "      <td>111021</td>\n",
       "      <td>11</td>\n",
       "      <td>Management</td>\n",
       "      <td>0</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>No major</td>\n",
       "      <td>No major</td>\n",
       "      <td>19</td>\n",
       "      <td>1 or more years of college credit, no degree</td>\n",
       "      <td>19</td>\n",
       "      <td>99</td>\n",
       "      <td>No major</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SERIALNO    SOCP MAJ_SOCP                    MAJ_SOCP_labels  MAJ_SOCP_15 FOD1P FOD2P FOD1P_labels FOD2P_labels SCHL                                   SCHL_labels  SCHL_ord  FOD1P_MAJ FOD1P_MAJ_labels  FOD1P_MAJ__Agriculture, agriculture operations, and related sciences  FOD1P_MAJ__Architecture and related services  FOD1P_MAJ__Area, ethnic, cultural, gender, and group studies  FOD1P_MAJ__Biological and biomedical sciences  FOD1P_MAJ__Business, management, marketing, and related support services  FOD1P_MAJ__Communication, journalism, and related programs  FOD1P_MAJ__Communications technologies/technicians and support services  FOD1P_MAJ__Computer and information sciences and support services  FOD1P_MAJ__Construction trades  FOD1P_MAJ__Education  FOD1P_MAJ__Engineering  FOD1P_MAJ__Engineering technologies and engineering-related fields  FOD1P_MAJ__English language and literature/letters  FOD1P_MAJ__Family and consumer sciences/human sciences  \\\n",
       "40527  2017000772957  119021       11                         Management            0  9999  9999     No major     No major   17                 GED or alternative credential        17         99         No major                                                  0                                                                0                                                  0                                                         0                                                  0                                                                         0                                                           0                                                                        0                                               0                     0                       0                                                  0                                                                   0                                                   0        \n",
       "31850  2017000607027  131161       13  Business and Financial Operations            0  5501  9999    Economics     No major   21                             Bachelor's degree        21         55  Social sciences                                                  0                                                                0                                                  0                                                         0                                                  0                                                                         0                                                           0                                                                        0                                               0                     0                       0                                                  0                                                                   0                                                   0        \n",
       "76207  2017001499692  111021       11                         Management            0  9999  9999     No major     No major   19  1 or more years of college credit, no degree        19         99         No major                                                  0                                                                0                                                  0                                                         0                                                  0                                                                         0                                                           0                                                                        0                                               0                     0                       0                                                  0                                                                   0                                                   0        \n",
       "\n",
       "       FOD1P_MAJ__Foreign languages, literatures, and linguistics  FOD1P_MAJ__Health professions and related programs  FOD1P_MAJ__History  FOD1P_MAJ__Homeland security, law enforcement, firefighting and related protective services  FOD1P_MAJ__Legal professions and studies  FOD1P_MAJ__Liberal arts and sciences, general studies and humanities  FOD1P_MAJ__Library science  FOD1P_MAJ__Mathematics and statistics  FOD1P_MAJ__Mechanic and repair technologies/technicians  FOD1P_MAJ__Military science, leadership and operational art  FOD1P_MAJ__Multi/interdisciplinary studies  FOD1P_MAJ__Natural resources and conservation  FOD1P_MAJ__No major  FOD1P_MAJ__Parks, recreation, leisure, and fitness studies  FOD1P_MAJ__Personal and culinary services  FOD1P_MAJ__Philosophy and religious studies  FOD1P_MAJ__Physical sciences  FOD1P_MAJ__Psychology  FOD1P_MAJ__Public administration and social service professions  FOD1P_MAJ__Science technologies/technicians  FOD1P_MAJ__Social sciences  \\\n",
       "40527                                                  0                                                           0                    0                                                  0                                                                                   0                                                  0                                              0                                      0                                                  0                                                        0                                                     0                                              0                    1                                                  0                                                   0                                            0                             0                      0                                                  0                                                          0                           0   \n",
       "31850                                                  0                                                           0                    0                                                  0                                                                                   0                                                  0                                              0                                      0                                                  0                                                        0                                                     0                                              0                    0                                                  0                                                   0                                            0                             0                      0                                                  0                                                          0                           1   \n",
       "76207                                                  0                                                           0                    0                                                  0                                                                                   0                                                  0                                              0                                      0                                                  0                                                        0                                                     0                                              0                    1                                                  0                                                   0                                            0                             0                      0                                                  0                                                          0                           0   \n",
       "\n",
       "       FOD1P_MAJ__Theology and religious vocations  FOD1P_MAJ__Transportation and materials moving  FOD1P_MAJ__Visual and performing arts  FOD1P__Accounting  FOD1P__Actuarial Science  FOD1P__Advertising And Public Relations  FOD1P__Aerospace Engineering  FOD1P__Agricultural Economics  FOD1P__Agriculture Production And Management  FOD1P__Animal Sciences  FOD1P__Anthropology And Archeology  FOD1P__Applied Mathematics  FOD1P__Architectural Engineering  FOD1P__Architecture  FOD1P__Area Ethnic And Civilization Studies  FOD1P__Art And Music Education  FOD1P__Art History And Criticism  FOD1P__Astronomy And Astrophysics  FOD1P__Atmospheric Sciences And Meteorology  FOD1P__Biochemical Sciences  FOD1P__Biological Engineering  FOD1P__Biology  FOD1P__Biomedical Engineering  FOD1P__Botany  FOD1P__Business Economics  FOD1P__Business Management And Administration  FOD1P__Chemical Engineering  FOD1P__Chemistry  FOD1P__Civil Engineering  FOD1P__Clinical Psychology  \\\n",
       "40527                                            0                                               0                                      0                  0                         0                                        0                             0                              0                                             0                       0                                   0                           0                                 0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0              0                          0                                              0                            0                 0                         0                           0   \n",
       "31850                                            0                                               0                                      0                  0                         0                                        0                             0                              0                                             0                       0                                   0                           0                                 0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0              0                          0                                              0                            0                 0                         0                           0   \n",
       "76207                                            0                                               0                                      0                  0                         0                                        0                             0                              0                                             0                       0                                   0                           0                                 0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0              0                          0                                              0                            0                 0                         0                           0   \n",
       "\n",
       "       FOD1P__Cognitive Science And Biopsychology  FOD1P__Commercial Art And Graphic Design  FOD1P__Communication Disorders Sciences And Services  FOD1P__Communication Technologies  FOD1P__Communications  FOD1P__Community And Public Health  FOD1P__Composition And Rhetoric  FOD1P__Computer Administration Management And Security  FOD1P__Computer And Information Systems  FOD1P__Computer Engineering  FOD1P__Computer Networking And Telecommunications  FOD1P__Computer Programming And Data Processing  FOD1P__Computer Science  FOD1P__Construction Services  FOD1P__Cosmetology Services And Culinary Arts  FOD1P__Counseling Psychology  FOD1P__Court Reporting  FOD1P__Criminal Justice And Fire Protection  FOD1P__Criminology  FOD1P__Drama And Theater Arts  FOD1P__Early Childhood Education  FOD1P__Ecology  FOD1P__Economics  FOD1P__Educational Administration And Supervision  FOD1P__Educational Psychology  FOD1P__Electrical Engineering  FOD1P__Electrical Engineering Technology  \\\n",
       "40527                                           0                                         0                                                  0                                     0                      0                                   0                                0                                                  0                                             0                            0                                                  0                                                0                        0                             0                                              0                             0                       0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0   \n",
       "31850                                           0                                         0                                                  0                                     0                      0                                   0                                0                                                  0                                             0                            0                                                  0                                                0                        0                             0                                              0                             0                       0                                            0                   0                              0                                 0               0                 1                                                  0                              0                              0                                         0   \n",
       "76207                                           0                                         0                                                  0                                     0                      0                                   0                                0                                                  0                                             0                            0                                                  0                                                0                        0                             0                                              0                             0                       0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0   \n",
       "\n",
       "       FOD1P__Electrical, Mechanical, And Precision Technologies And Production  FOD1P__Elementary Education  FOD1P__Engineering And Industrial Management  FOD1P__Engineering Mechanics Physics And Science  FOD1P__Engineering Technologies  FOD1P__English Language And Literature  FOD1P__Environmental Engineering  FOD1P__Environmental Science  FOD1P__Family And Consumer Sciences  FOD1P__Film Video And Photographic Arts  FOD1P__Finance  FOD1P__Fine Arts  FOD1P__Food Science  FOD1P__Forestry  FOD1P__French German Latin And Other Common Foreign Language Studies  FOD1P__General Agriculture  FOD1P__General Business  FOD1P__General Education  FOD1P__General Engineering  FOD1P__General Medical And Health Services  FOD1P__General Social Sciences  FOD1P__Genetics  FOD1P__Geography  FOD1P__Geological And Geophysical Engineering  FOD1P__Geology And Earth Science  FOD1P__Geosciences  FOD1P__Health And Medical Administrative Services  FOD1P__Health And Medical Preparatory Programs  FOD1P__History  \\\n",
       "40527                                                  0                                                   0                                             0                                                 0                                0                                       0                                 0                             0                                    0                                        0               0                 0                    0                0                                                  0                                              0                        0                         0                           0                                           0                               0                0                 0                                              0                                 0                   0                                                  0                                               0               0   \n",
       "31850                                                  0                                                   0                                             0                                                 0                                0                                       0                                 0                             0                                    0                                        0               0                 0                    0                0                                                  0                                              0                        0                         0                           0                                           0                               0                0                 0                                              0                                 0                   0                                                  0                                               0               0   \n",
       "76207                                                  0                                                   0                                             0                                                 0                                0                                       0                                 0                             0                                    0                                        0               0                 0                    0                0                                                  0                                              0                        0                         0                           0                                           0                               0                0                 0                                              0                                 0                   0                                                  0                                               0               0   \n",
       "\n",
       "       FOD1P__Hospitality Management  FOD1P__Human Resources And Personnel Management  FOD1P__Human Services And Community Organization  FOD1P__Humanities  FOD1P__Industrial And Manufacturing Engineering  FOD1P__Industrial And Organizational Psychology  FOD1P__Industrial Production Technologies  FOD1P__Information Sciences  FOD1P__Intercultural And International Studies  FOD1P__Interdisciplinary Social Sciences  FOD1P__International Business  FOD1P__International Relations  FOD1P__Journalism  FOD1P__Language And Drama Education  FOD1P__Liberal Arts  FOD1P__Library Science  FOD1P__Linguistics And Comparative Language And Literature  FOD1P__Management Information Systems And Statistics  FOD1P__Marketing And Marketing Research  FOD1P__Mass Media  FOD1P__Materials Engineering And Materials Science  FOD1P__Materials Science  FOD1P__Mathematics  FOD1P__Mathematics And Computer Science  FOD1P__Mathematics Teacher Education  FOD1P__Mechanical Engineering  \\\n",
       "40527                              0                                                0                                                 0                  0                                                0                                                0                                          0                            0                                               0                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                                     0                              0   \n",
       "31850                              0                                                0                                                 0                  0                                                0                                                0                                          0                            0                                               0                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                                     0                              0   \n",
       "76207                              0                                                0                                                 0                  0                                                0                                                0                                          0                            0                                               0                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                                     0                              0   \n",
       "\n",
       "       FOD1P__Mechanical Engineering Related Technologies  FOD1P__Medical Assisting Services  FOD1P__Medical Technologies Technicians  FOD1P__Metallurgical Engineering  FOD1P__Microbiology  FOD1P__Military Technologies  FOD1P__Mining And Mineral Engineering  FOD1P__Miscellaneous Agriculture  FOD1P__Miscellaneous Biology  FOD1P__Miscellaneous Business & Medical Administration  FOD1P__Miscellaneous Education  FOD1P__Miscellaneous Engineering  FOD1P__Miscellaneous Engineering Technologies  FOD1P__Miscellaneous Fine Arts  FOD1P__Miscellaneous Health Medical Professions  FOD1P__Miscellaneous Psychology  FOD1P__Miscellaneous Social Sciences  FOD1P__Molecular Biology  FOD1P__Multi-Disciplinary Or General Science  FOD1P__Multi/Interdisciplinary Studies  FOD1P__Music  FOD1P__Natural Resources Management  FOD1P__Naval Architecture And Marine Engineering  FOD1P__Neuroscience  FOD1P__No major  FOD1P__Nuclear Engineering  FOD1P__Nuclear, Industrial Radiology, And Biological Technologies  \\\n",
       "40527                                                  0                                   0                                        0                                 0                    0                             0                                      0                                 0                             0                                                  0                                    0                                 0                                              0                               0                                                0                                0                                     0                         0                                             0                                       0             0                                    0                                                 0                    0                1                           0                                                  0                   \n",
       "31850                                                  0                                   0                                        0                                 0                    0                             0                                      0                                 0                             0                                                  0                                    0                                 0                                              0                               0                                                0                                0                                     0                         0                                             0                                       0             0                                    0                                                 0                    0                0                           0                                                  0                   \n",
       "76207                                                  0                                   0                                        0                                 0                    0                             0                                      0                                 0                             0                                                  0                                    0                                 0                                              0                               0                                                0                                0                                     0                         0                                             0                                       0             0                                    0                                                 0                    0                1                           0                                                  0                   \n",
       "\n",
       "       FOD1P__Nursing  FOD1P__Nutrition Sciences  FOD1P__Oceanography  FOD1P__Operations Logistics And E-Commerce  FOD1P__Other Foreign Languages  FOD1P__Petroleum Engineering  FOD1P__Pharmacology  FOD1P__Pharmacy Pharmaceutical Sciences And Administration  FOD1P__Philosophy And Religious Studies  FOD1P__Physical And Health Education Teaching  FOD1P__Physical Fitness Parks Recreation And Leisure  FOD1P__Physical Sciences  FOD1P__Physics  FOD1P__Physiology  FOD1P__Plant Science And Agronomy  FOD1P__Political Science And Government  FOD1P__Pre-Law And Legal Studies  FOD1P__Psychology  FOD1P__Public Administration  FOD1P__Public Policy  FOD1P__School Student Counseling  FOD1P__Science And Computer Teacher Education  FOD1P__Secondary Teacher Education  FOD1P__Social Psychology  FOD1P__Social Science Or History Teacher Education  FOD1P__Social Work  FOD1P__Sociology  FOD1P__Soil Science  FOD1P__Special Needs Education  FOD1P__Statistics And Decision Science  FOD1P__Studio Arts  \\\n",
       "40527               0                          0                    0                                           0                               0                             0                    0                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                 0                                              0                                   0                         0                                                  0                    0                 0                    0                               0                                       0                   0   \n",
       "31850               0                          0                    0                                           0                               0                             0                    0                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                 0                                              0                                   0                         0                                                  0                    0                 0                    0                               0                                       0                   0   \n",
       "76207               0                          0                    0                                           0                               0                             0                    0                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                 0                                              0                                   0                         0                                                  0                    0                 0                    0                               0                                       0                   0   \n",
       "\n",
       "       FOD1P__Teacher Education: Multiple Levels  FOD1P__Theology And Religious Vocations  FOD1P__Transportation Sciences And Technologies  FOD1P__Treatment Therapy Professions  FOD1P__United States History  FOD1P__Visual And Performing Arts  FOD1P__Zoology  FOD2P__Accounting  FOD2P__Advertising And Public Relations  FOD2P__Aerospace Engineering  FOD2P__Agriculture Production And Management  FOD2P__Animal Sciences  FOD2P__Anthropology And Archeology  FOD2P__Applied Mathematics  FOD2P__Architecture  FOD2P__Area Ethnic And Civilization Studies  FOD2P__Art And Music Education  FOD2P__Art History And Criticism  FOD2P__Astronomy And Astrophysics  FOD2P__Atmospheric Sciences And Meteorology  FOD2P__Biochemical Sciences  FOD2P__Biological Engineering  FOD2P__Biology  FOD2P__Biomedical Engineering  FOD2P__Business Economics  FOD2P__Business Management And Administration  FOD2P__Chemistry  FOD2P__Civil Engineering  FOD2P__Clinical Psychology  FOD2P__Cognitive Science And Biopsychology  \\\n",
       "40527                                          0                                        0                                                0                                     0                             0                                  0               0                  0                                        0                             0                                             0                       0                                   0                           0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0                          0                                              0                 0                         0                           0                                           0   \n",
       "31850                                          0                                        0                                                0                                     0                             0                                  0               0                  0                                        0                             0                                             0                       0                                   0                           0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0                          0                                              0                 0                         0                           0                                           0   \n",
       "76207                                          0                                        0                                                0                                     0                             0                                  0               0                  0                                        0                             0                                             0                       0                                   0                           0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0                          0                                              0                 0                         0                           0                                           0   \n",
       "\n",
       "       FOD2P__Commercial Art And Graphic Design  FOD2P__Communication Disorders Sciences And Services  FOD2P__Communication Technologies  FOD2P__Communications  FOD2P__Community And Public Health  FOD2P__Composition And Rhetoric  FOD2P__Computer Administration Management And Security  FOD2P__Computer And Information Systems  FOD2P__Computer Engineering  FOD2P__Computer Networking And Telecommunications  FOD2P__Computer Programming And Data Processing  FOD2P__Computer Science  FOD2P__Cosmetology Services And Culinary Arts  FOD2P__Counseling Psychology  FOD2P__Criminal Justice And Fire Protection  FOD2P__Criminology  FOD2P__Drama And Theater Arts  FOD2P__Early Childhood Education  FOD2P__Ecology  FOD2P__Economics  FOD2P__Educational Administration And Supervision  FOD2P__Educational Psychology  FOD2P__Electrical Engineering  FOD2P__Electrical Engineering Technology  FOD2P__Electrical, Mechanical, And Precision Technologies And Production  FOD2P__Elementary Education  \\\n",
       "40527                                         0                                                  0                                     0                      0                                   0                                0                                                  0                                             0                            0                                                  0                                                0                        0                                              0                             0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0   \n",
       "31850                                         0                                                  0                                     0                      0                                   0                                0                                                  0                                             0                            0                                                  0                                                0                        0                                              0                             0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0   \n",
       "76207                                         0                                                  0                                     0                      0                                   0                                0                                                  0                                             0                            0                                                  0                                                0                        0                                              0                             0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0   \n",
       "\n",
       "       FOD2P__Engineering And Industrial Management  FOD2P__Engineering Mechanics Physics And Science  FOD2P__Engineering Technologies  FOD2P__English Language And Literature  FOD2P__Environmental Engineering  FOD2P__Environmental Science  FOD2P__Family And Consumer Sciences  FOD2P__Film Video And Photographic Arts  FOD2P__Finance  FOD2P__Fine Arts  FOD2P__Food Science  FOD2P__Forestry  FOD2P__French German Latin And Other Common Foreign Language Studies  FOD2P__General Business  FOD2P__General Education  FOD2P__General Engineering  FOD2P__General Medical And Health Services  FOD2P__General Social Sciences  FOD2P__Genetics  FOD2P__Geography  FOD2P__Geology And Earth Science  FOD2P__Geosciences  FOD2P__Health And Medical Administrative Services  FOD2P__Health And Medical Preparatory Programs  FOD2P__History  FOD2P__Hospitality Management  FOD2P__Human Resources And Personnel Management  FOD2P__Human Services And Community Organization  FOD2P__Humanities  \\\n",
       "40527                                             0                                                 0                                0                                       0                                 0                             0                                    0                                        0               0                 0                    0                0                                                  0                                           0                         0                           0                                           0                               0                0                 0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0   \n",
       "31850                                             0                                                 0                                0                                       0                                 0                             0                                    0                                        0               0                 0                    0                0                                                  0                                           0                         0                           0                                           0                               0                0                 0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0   \n",
       "76207                                             0                                                 0                                0                                       0                                 0                             0                                    0                                        0               0                 0                    0                0                                                  0                                           0                         0                           0                                           0                               0                0                 0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0   \n",
       "\n",
       "       FOD2P__Industrial And Manufacturing Engineering  FOD2P__Industrial And Organizational Psychology  FOD2P__Industrial Production Technologies  FOD2P__Information Sciences  FOD2P__Intercultural And International Studies  FOD2P__Interdisciplinary Social Sciences  FOD2P__International Business  FOD2P__International Relations  FOD2P__Journalism  FOD2P__Language And Drama Education  FOD2P__Liberal Arts  FOD2P__Library Science  FOD2P__Linguistics And Comparative Language And Literature  FOD2P__Management Information Systems And Statistics  FOD2P__Marketing And Marketing Research  FOD2P__Mass Media  FOD2P__Materials Engineering And Materials Science  FOD2P__Materials Science  FOD2P__Mathematics  FOD2P__Mathematics And Computer Science  FOD2P__Mechanical Engineering  FOD2P__Medical Assisting Services  FOD2P__Medical Technologies Technicians  FOD2P__Metallurgical Engineering  FOD2P__Microbiology  FOD2P__Miscellaneous Biology  FOD2P__Miscellaneous Business & Medical Administration  \\\n",
       "40527                                                0                                                0                                          0                            0                                               0                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                              0                                  0                                        0                                 0                    0                             0                                                  0        \n",
       "31850                                                0                                                0                                          0                            0                                               0                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                              0                                  0                                        0                                 0                    0                             0                                                  0        \n",
       "76207                                                0                                                0                                          0                            0                                               0                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                              0                                  0                                        0                                 0                    0                             0                                                  0        \n",
       "\n",
       "       FOD2P__Miscellaneous Education  FOD2P__Miscellaneous Engineering  FOD2P__Miscellaneous Engineering Technologies  FOD2P__Miscellaneous Fine Arts  FOD2P__Miscellaneous Health Medical Professions  FOD2P__Miscellaneous Psychology  FOD2P__Miscellaneous Social Sciences  FOD2P__Molecular Biology  FOD2P__Multi-Disciplinary Or General Science  FOD2P__Multi/Interdisciplinary Studies  FOD2P__Music  FOD2P__Natural Resources Management  FOD2P__Neuroscience  FOD2P__No major  FOD2P__Nursing  FOD2P__Nutrition Sciences  FOD2P__Oceanography  FOD2P__Operations Logistics And E-Commerce  FOD2P__Other Foreign Languages  FOD2P__Pharmacy Pharmaceutical Sciences And Administration  FOD2P__Philosophy And Religious Studies  FOD2P__Physical And Health Education Teaching  FOD2P__Physical Fitness Parks Recreation And Leisure  FOD2P__Physical Sciences  FOD2P__Physics  FOD2P__Physiology  FOD2P__Plant Science And Agronomy  FOD2P__Political Science And Government  FOD2P__Pre-Law And Legal Studies  \\\n",
       "40527                               0                                 0                                              0                               0                                                0                                0                                     0                         0                                             0                                       0             0                                    0                    0                1               0                          0                    0                                           0                               0                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0   \n",
       "31850                               0                                 0                                              0                               0                                                0                                0                                     0                         0                                             0                                       0             0                                    0                    0                1               0                          0                    0                                           0                               0                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0   \n",
       "76207                               0                                 0                                              0                               0                                                0                                0                                     0                         0                                             0                                       0             0                                    0                    0                1               0                          0                    0                                           0                               0                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0   \n",
       "\n",
       "       FOD2P__Psychology  FOD2P__Public Administration  FOD2P__Public Policy  FOD2P__Science And Computer Teacher Education  FOD2P__Secondary Teacher Education  FOD2P__Social Science Or History Teacher Education  FOD2P__Social Work  FOD2P__Sociology  FOD2P__Soil Science  FOD2P__Special Needs Education  FOD2P__Statistics And Decision Science  FOD2P__Studio Arts  FOD2P__Theology And Religious Vocations  FOD2P__Treatment Therapy Professions  FOD2P__United States History  FOD2P__Visual And Performing Arts  FOD2P__Zoology  SCHL__1 or more years of college credit, no degree  SCHL__12th grade - no diploma  SCHL__Associate's degree  SCHL__Bachelor's degree  SCHL__Doctorate degree  SCHL__GED or alternative credential  SCHL__Grade 1  SCHL__Grade 10  SCHL__Grade 11  SCHL__Grade 2  SCHL__Grade 3  SCHL__Grade 4  SCHL__Grade 5  SCHL__Grade 6  SCHL__Grade 7  SCHL__Grade 8  SCHL__Grade 9  SCHL__Kindergarten  SCHL__Master's degree  SCHL__No schooling completed  SCHL__Nursery school, preschool  \\\n",
       "40527                  0                             0                     0                                              0                                   0                                                  0                    0                 0                    0                               0                                       0                   0                                        0                                     0                             0                                  0               0                                                  0                               0                         0                        0                       0                                    1              0               0               0              0              0              0              0              0              0              0              0                   0                      0                             0                                0   \n",
       "31850                  0                             0                     0                                              0                                   0                                                  0                    0                 0                    0                               0                                       0                   0                                        0                                     0                             0                                  0               0                                                  0                               0                         0                        1                       0                                    0              0               0               0              0              0              0              0              0              0              0              0                   0                      0                             0                                0   \n",
       "76207                  0                             0                     0                                              0                                   0                                                  0                    0                 0                    0                               0                                       0                   0                                        0                                     0                             0                                  0               0                                                  1                               0                         0                        0                       0                                    0              0               0               0              0              0              0              0              0              0              0              0                   0                      0                             0                                0   \n",
       "\n",
       "       SCHL__Professional degree beyond a bachelor's degree  SCHL__Regular high school diploma  SCHL__Some college, but less than 1 year  \n",
       "40527                                                  0                                     0                                         0  \n",
       "31850                                                  0                                     0                                         0  \n",
       "76207                                                  0                                     0                                         0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X = edu_df.drop(columns=[ 'SERIALNO', 'FOD1P', 'FOD2P','SOCP','MAJ_SOCP','MAJ_SOCP_labels', \n",
    "                'MAJ_SOCP_15','FOD1P_labels','FOD2P_labels','SCHL',\n",
    "                'SCHL_labels','FOD1P_MAJ_labels', 'FOD1P_MAJ'])\n",
    "y = edu_df.loc[:,'MAJ_SOCP_15']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54184, 388)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL_ord</th>\n",
       "      <th>FOD1P_MAJ__Agriculture, agriculture operations, and related sciences</th>\n",
       "      <th>FOD1P_MAJ__Architecture and related services</th>\n",
       "      <th>FOD1P_MAJ__Area, ethnic, cultural, gender, and group studies</th>\n",
       "      <th>FOD1P_MAJ__Biological and biomedical sciences</th>\n",
       "      <th>FOD1P_MAJ__Business, management, marketing, and related support services</th>\n",
       "      <th>FOD1P_MAJ__Communication, journalism, and related programs</th>\n",
       "      <th>FOD1P_MAJ__Communications technologies/technicians and support services</th>\n",
       "      <th>FOD1P_MAJ__Computer and information sciences and support services</th>\n",
       "      <th>FOD1P_MAJ__Construction trades</th>\n",
       "      <th>FOD1P_MAJ__Education</th>\n",
       "      <th>FOD1P_MAJ__Engineering</th>\n",
       "      <th>FOD1P_MAJ__Engineering technologies and engineering-related fields</th>\n",
       "      <th>FOD1P_MAJ__English language and literature/letters</th>\n",
       "      <th>FOD1P_MAJ__Family and consumer sciences/human sciences</th>\n",
       "      <th>FOD1P_MAJ__Foreign languages, literatures, and linguistics</th>\n",
       "      <th>FOD1P_MAJ__Health professions and related programs</th>\n",
       "      <th>FOD1P_MAJ__History</th>\n",
       "      <th>FOD1P_MAJ__Homeland security, law enforcement, firefighting and related protective services</th>\n",
       "      <th>FOD1P_MAJ__Legal professions and studies</th>\n",
       "      <th>FOD1P_MAJ__Liberal arts and sciences, general studies and humanities</th>\n",
       "      <th>FOD1P_MAJ__Library science</th>\n",
       "      <th>FOD1P_MAJ__Mathematics and statistics</th>\n",
       "      <th>FOD1P_MAJ__Mechanic and repair technologies/technicians</th>\n",
       "      <th>FOD1P_MAJ__Military science, leadership and operational art</th>\n",
       "      <th>FOD1P_MAJ__Multi/interdisciplinary studies</th>\n",
       "      <th>FOD1P_MAJ__Natural resources and conservation</th>\n",
       "      <th>FOD1P_MAJ__No major</th>\n",
       "      <th>FOD1P_MAJ__Parks, recreation, leisure, and fitness studies</th>\n",
       "      <th>FOD1P_MAJ__Personal and culinary services</th>\n",
       "      <th>FOD1P_MAJ__Philosophy and religious studies</th>\n",
       "      <th>FOD1P_MAJ__Physical sciences</th>\n",
       "      <th>FOD1P_MAJ__Psychology</th>\n",
       "      <th>FOD1P_MAJ__Public administration and social service professions</th>\n",
       "      <th>FOD1P_MAJ__Science technologies/technicians</th>\n",
       "      <th>FOD1P_MAJ__Social sciences</th>\n",
       "      <th>FOD1P_MAJ__Theology and religious vocations</th>\n",
       "      <th>FOD1P_MAJ__Transportation and materials moving</th>\n",
       "      <th>FOD1P_MAJ__Visual and performing arts</th>\n",
       "      <th>FOD1P__Accounting</th>\n",
       "      <th>FOD1P__Actuarial Science</th>\n",
       "      <th>FOD1P__Advertising And Public Relations</th>\n",
       "      <th>FOD1P__Aerospace Engineering</th>\n",
       "      <th>FOD1P__Agricultural Economics</th>\n",
       "      <th>FOD1P__Agriculture Production And Management</th>\n",
       "      <th>FOD1P__Animal Sciences</th>\n",
       "      <th>FOD1P__Anthropology And Archeology</th>\n",
       "      <th>FOD1P__Applied Mathematics</th>\n",
       "      <th>FOD1P__Architectural Engineering</th>\n",
       "      <th>FOD1P__Architecture</th>\n",
       "      <th>FOD1P__Area Ethnic And Civilization Studies</th>\n",
       "      <th>FOD1P__Art And Music Education</th>\n",
       "      <th>FOD1P__Art History And Criticism</th>\n",
       "      <th>FOD1P__Astronomy And Astrophysics</th>\n",
       "      <th>FOD1P__Atmospheric Sciences And Meteorology</th>\n",
       "      <th>FOD1P__Biochemical Sciences</th>\n",
       "      <th>FOD1P__Biological Engineering</th>\n",
       "      <th>FOD1P__Biology</th>\n",
       "      <th>FOD1P__Biomedical Engineering</th>\n",
       "      <th>FOD1P__Botany</th>\n",
       "      <th>FOD1P__Business Economics</th>\n",
       "      <th>FOD1P__Business Management And Administration</th>\n",
       "      <th>FOD1P__Chemical Engineering</th>\n",
       "      <th>FOD1P__Chemistry</th>\n",
       "      <th>FOD1P__Civil Engineering</th>\n",
       "      <th>FOD1P__Clinical Psychology</th>\n",
       "      <th>FOD1P__Cognitive Science And Biopsychology</th>\n",
       "      <th>FOD1P__Commercial Art And Graphic Design</th>\n",
       "      <th>FOD1P__Communication Disorders Sciences And Services</th>\n",
       "      <th>FOD1P__Communication Technologies</th>\n",
       "      <th>FOD1P__Communications</th>\n",
       "      <th>FOD1P__Community And Public Health</th>\n",
       "      <th>FOD1P__Composition And Rhetoric</th>\n",
       "      <th>FOD1P__Computer Administration Management And Security</th>\n",
       "      <th>FOD1P__Computer And Information Systems</th>\n",
       "      <th>FOD1P__Computer Engineering</th>\n",
       "      <th>FOD1P__Computer Networking And Telecommunications</th>\n",
       "      <th>FOD1P__Computer Programming And Data Processing</th>\n",
       "      <th>FOD1P__Computer Science</th>\n",
       "      <th>FOD1P__Construction Services</th>\n",
       "      <th>FOD1P__Cosmetology Services And Culinary Arts</th>\n",
       "      <th>FOD1P__Counseling Psychology</th>\n",
       "      <th>FOD1P__Court Reporting</th>\n",
       "      <th>FOD1P__Criminal Justice And Fire Protection</th>\n",
       "      <th>FOD1P__Criminology</th>\n",
       "      <th>FOD1P__Drama And Theater Arts</th>\n",
       "      <th>FOD1P__Early Childhood Education</th>\n",
       "      <th>FOD1P__Ecology</th>\n",
       "      <th>FOD1P__Economics</th>\n",
       "      <th>FOD1P__Educational Administration And Supervision</th>\n",
       "      <th>FOD1P__Educational Psychology</th>\n",
       "      <th>FOD1P__Electrical Engineering</th>\n",
       "      <th>FOD1P__Electrical Engineering Technology</th>\n",
       "      <th>FOD1P__Electrical, Mechanical, And Precision Technologies And Production</th>\n",
       "      <th>FOD1P__Elementary Education</th>\n",
       "      <th>FOD1P__Engineering And Industrial Management</th>\n",
       "      <th>FOD1P__Engineering Mechanics Physics And Science</th>\n",
       "      <th>FOD1P__Engineering Technologies</th>\n",
       "      <th>FOD1P__English Language And Literature</th>\n",
       "      <th>FOD1P__Environmental Engineering</th>\n",
       "      <th>FOD1P__Environmental Science</th>\n",
       "      <th>FOD1P__Family And Consumer Sciences</th>\n",
       "      <th>FOD1P__Film Video And Photographic Arts</th>\n",
       "      <th>FOD1P__Finance</th>\n",
       "      <th>FOD1P__Fine Arts</th>\n",
       "      <th>FOD1P__Food Science</th>\n",
       "      <th>FOD1P__Forestry</th>\n",
       "      <th>FOD1P__French German Latin And Other Common Foreign Language Studies</th>\n",
       "      <th>FOD1P__General Agriculture</th>\n",
       "      <th>FOD1P__General Business</th>\n",
       "      <th>FOD1P__General Education</th>\n",
       "      <th>FOD1P__General Engineering</th>\n",
       "      <th>FOD1P__General Medical And Health Services</th>\n",
       "      <th>FOD1P__General Social Sciences</th>\n",
       "      <th>FOD1P__Genetics</th>\n",
       "      <th>FOD1P__Geography</th>\n",
       "      <th>FOD1P__Geological And Geophysical Engineering</th>\n",
       "      <th>FOD1P__Geology And Earth Science</th>\n",
       "      <th>FOD1P__Geosciences</th>\n",
       "      <th>FOD1P__Health And Medical Administrative Services</th>\n",
       "      <th>FOD1P__Health And Medical Preparatory Programs</th>\n",
       "      <th>FOD1P__History</th>\n",
       "      <th>FOD1P__Hospitality Management</th>\n",
       "      <th>FOD1P__Human Resources And Personnel Management</th>\n",
       "      <th>FOD1P__Human Services And Community Organization</th>\n",
       "      <th>FOD1P__Humanities</th>\n",
       "      <th>FOD1P__Industrial And Manufacturing Engineering</th>\n",
       "      <th>FOD1P__Industrial And Organizational Psychology</th>\n",
       "      <th>FOD1P__Industrial Production Technologies</th>\n",
       "      <th>FOD1P__Information Sciences</th>\n",
       "      <th>FOD1P__Intercultural And International Studies</th>\n",
       "      <th>FOD1P__Interdisciplinary Social Sciences</th>\n",
       "      <th>FOD1P__International Business</th>\n",
       "      <th>FOD1P__International Relations</th>\n",
       "      <th>FOD1P__Journalism</th>\n",
       "      <th>FOD1P__Language And Drama Education</th>\n",
       "      <th>FOD1P__Liberal Arts</th>\n",
       "      <th>FOD1P__Library Science</th>\n",
       "      <th>FOD1P__Linguistics And Comparative Language And Literature</th>\n",
       "      <th>FOD1P__Management Information Systems And Statistics</th>\n",
       "      <th>FOD1P__Marketing And Marketing Research</th>\n",
       "      <th>FOD1P__Mass Media</th>\n",
       "      <th>FOD1P__Materials Engineering And Materials Science</th>\n",
       "      <th>FOD1P__Materials Science</th>\n",
       "      <th>FOD1P__Mathematics</th>\n",
       "      <th>FOD1P__Mathematics And Computer Science</th>\n",
       "      <th>FOD1P__Mathematics Teacher Education</th>\n",
       "      <th>FOD1P__Mechanical Engineering</th>\n",
       "      <th>FOD1P__Mechanical Engineering Related Technologies</th>\n",
       "      <th>FOD1P__Medical Assisting Services</th>\n",
       "      <th>FOD1P__Medical Technologies Technicians</th>\n",
       "      <th>FOD1P__Metallurgical Engineering</th>\n",
       "      <th>FOD1P__Microbiology</th>\n",
       "      <th>FOD1P__Military Technologies</th>\n",
       "      <th>FOD1P__Mining And Mineral Engineering</th>\n",
       "      <th>FOD1P__Miscellaneous Agriculture</th>\n",
       "      <th>FOD1P__Miscellaneous Biology</th>\n",
       "      <th>FOD1P__Miscellaneous Business &amp; Medical Administration</th>\n",
       "      <th>FOD1P__Miscellaneous Education</th>\n",
       "      <th>FOD1P__Miscellaneous Engineering</th>\n",
       "      <th>FOD1P__Miscellaneous Engineering Technologies</th>\n",
       "      <th>FOD1P__Miscellaneous Fine Arts</th>\n",
       "      <th>FOD1P__Miscellaneous Health Medical Professions</th>\n",
       "      <th>FOD1P__Miscellaneous Psychology</th>\n",
       "      <th>FOD1P__Miscellaneous Social Sciences</th>\n",
       "      <th>FOD1P__Molecular Biology</th>\n",
       "      <th>FOD1P__Multi-Disciplinary Or General Science</th>\n",
       "      <th>FOD1P__Multi/Interdisciplinary Studies</th>\n",
       "      <th>FOD1P__Music</th>\n",
       "      <th>FOD1P__Natural Resources Management</th>\n",
       "      <th>FOD1P__Naval Architecture And Marine Engineering</th>\n",
       "      <th>FOD1P__Neuroscience</th>\n",
       "      <th>FOD1P__No major</th>\n",
       "      <th>FOD1P__Nuclear Engineering</th>\n",
       "      <th>FOD1P__Nuclear, Industrial Radiology, And Biological Technologies</th>\n",
       "      <th>FOD1P__Nursing</th>\n",
       "      <th>FOD1P__Nutrition Sciences</th>\n",
       "      <th>FOD1P__Oceanography</th>\n",
       "      <th>FOD1P__Operations Logistics And E-Commerce</th>\n",
       "      <th>FOD1P__Other Foreign Languages</th>\n",
       "      <th>FOD1P__Petroleum Engineering</th>\n",
       "      <th>FOD1P__Pharmacology</th>\n",
       "      <th>FOD1P__Pharmacy Pharmaceutical Sciences And Administration</th>\n",
       "      <th>FOD1P__Philosophy And Religious Studies</th>\n",
       "      <th>FOD1P__Physical And Health Education Teaching</th>\n",
       "      <th>FOD1P__Physical Fitness Parks Recreation And Leisure</th>\n",
       "      <th>FOD1P__Physical Sciences</th>\n",
       "      <th>FOD1P__Physics</th>\n",
       "      <th>FOD1P__Physiology</th>\n",
       "      <th>FOD1P__Plant Science And Agronomy</th>\n",
       "      <th>FOD1P__Political Science And Government</th>\n",
       "      <th>FOD1P__Pre-Law And Legal Studies</th>\n",
       "      <th>FOD1P__Psychology</th>\n",
       "      <th>FOD1P__Public Administration</th>\n",
       "      <th>FOD1P__Public Policy</th>\n",
       "      <th>FOD1P__School Student Counseling</th>\n",
       "      <th>FOD1P__Science And Computer Teacher Education</th>\n",
       "      <th>FOD1P__Secondary Teacher Education</th>\n",
       "      <th>FOD1P__Social Psychology</th>\n",
       "      <th>FOD1P__Social Science Or History Teacher Education</th>\n",
       "      <th>FOD1P__Social Work</th>\n",
       "      <th>FOD1P__Sociology</th>\n",
       "      <th>FOD1P__Soil Science</th>\n",
       "      <th>FOD1P__Special Needs Education</th>\n",
       "      <th>FOD1P__Statistics And Decision Science</th>\n",
       "      <th>FOD1P__Studio Arts</th>\n",
       "      <th>FOD1P__Teacher Education: Multiple Levels</th>\n",
       "      <th>FOD1P__Theology And Religious Vocations</th>\n",
       "      <th>FOD1P__Transportation Sciences And Technologies</th>\n",
       "      <th>FOD1P__Treatment Therapy Professions</th>\n",
       "      <th>FOD1P__United States History</th>\n",
       "      <th>FOD1P__Visual And Performing Arts</th>\n",
       "      <th>FOD1P__Zoology</th>\n",
       "      <th>FOD2P__Accounting</th>\n",
       "      <th>FOD2P__Advertising And Public Relations</th>\n",
       "      <th>FOD2P__Aerospace Engineering</th>\n",
       "      <th>FOD2P__Agriculture Production And Management</th>\n",
       "      <th>FOD2P__Animal Sciences</th>\n",
       "      <th>FOD2P__Anthropology And Archeology</th>\n",
       "      <th>FOD2P__Applied Mathematics</th>\n",
       "      <th>FOD2P__Architecture</th>\n",
       "      <th>FOD2P__Area Ethnic And Civilization Studies</th>\n",
       "      <th>FOD2P__Art And Music Education</th>\n",
       "      <th>FOD2P__Art History And Criticism</th>\n",
       "      <th>FOD2P__Astronomy And Astrophysics</th>\n",
       "      <th>FOD2P__Atmospheric Sciences And Meteorology</th>\n",
       "      <th>FOD2P__Biochemical Sciences</th>\n",
       "      <th>FOD2P__Biological Engineering</th>\n",
       "      <th>FOD2P__Biology</th>\n",
       "      <th>FOD2P__Biomedical Engineering</th>\n",
       "      <th>FOD2P__Business Economics</th>\n",
       "      <th>FOD2P__Business Management And Administration</th>\n",
       "      <th>FOD2P__Chemistry</th>\n",
       "      <th>FOD2P__Civil Engineering</th>\n",
       "      <th>FOD2P__Clinical Psychology</th>\n",
       "      <th>FOD2P__Cognitive Science And Biopsychology</th>\n",
       "      <th>FOD2P__Commercial Art And Graphic Design</th>\n",
       "      <th>FOD2P__Communication Disorders Sciences And Services</th>\n",
       "      <th>FOD2P__Communication Technologies</th>\n",
       "      <th>FOD2P__Communications</th>\n",
       "      <th>FOD2P__Community And Public Health</th>\n",
       "      <th>FOD2P__Composition And Rhetoric</th>\n",
       "      <th>FOD2P__Computer Administration Management And Security</th>\n",
       "      <th>FOD2P__Computer And Information Systems</th>\n",
       "      <th>FOD2P__Computer Engineering</th>\n",
       "      <th>FOD2P__Computer Networking And Telecommunications</th>\n",
       "      <th>FOD2P__Computer Programming And Data Processing</th>\n",
       "      <th>FOD2P__Computer Science</th>\n",
       "      <th>FOD2P__Cosmetology Services And Culinary Arts</th>\n",
       "      <th>FOD2P__Counseling Psychology</th>\n",
       "      <th>FOD2P__Criminal Justice And Fire Protection</th>\n",
       "      <th>FOD2P__Criminology</th>\n",
       "      <th>FOD2P__Drama And Theater Arts</th>\n",
       "      <th>FOD2P__Early Childhood Education</th>\n",
       "      <th>FOD2P__Ecology</th>\n",
       "      <th>FOD2P__Economics</th>\n",
       "      <th>FOD2P__Educational Administration And Supervision</th>\n",
       "      <th>FOD2P__Educational Psychology</th>\n",
       "      <th>FOD2P__Electrical Engineering</th>\n",
       "      <th>FOD2P__Electrical Engineering Technology</th>\n",
       "      <th>FOD2P__Electrical, Mechanical, And Precision Technologies And Production</th>\n",
       "      <th>FOD2P__Elementary Education</th>\n",
       "      <th>FOD2P__Engineering And Industrial Management</th>\n",
       "      <th>FOD2P__Engineering Mechanics Physics And Science</th>\n",
       "      <th>FOD2P__Engineering Technologies</th>\n",
       "      <th>FOD2P__English Language And Literature</th>\n",
       "      <th>FOD2P__Environmental Engineering</th>\n",
       "      <th>FOD2P__Environmental Science</th>\n",
       "      <th>FOD2P__Family And Consumer Sciences</th>\n",
       "      <th>FOD2P__Film Video And Photographic Arts</th>\n",
       "      <th>FOD2P__Finance</th>\n",
       "      <th>FOD2P__Fine Arts</th>\n",
       "      <th>FOD2P__Food Science</th>\n",
       "      <th>FOD2P__Forestry</th>\n",
       "      <th>FOD2P__French German Latin And Other Common Foreign Language Studies</th>\n",
       "      <th>FOD2P__General Business</th>\n",
       "      <th>FOD2P__General Education</th>\n",
       "      <th>FOD2P__General Engineering</th>\n",
       "      <th>FOD2P__General Medical And Health Services</th>\n",
       "      <th>FOD2P__General Social Sciences</th>\n",
       "      <th>FOD2P__Genetics</th>\n",
       "      <th>FOD2P__Geography</th>\n",
       "      <th>FOD2P__Geology And Earth Science</th>\n",
       "      <th>FOD2P__Geosciences</th>\n",
       "      <th>FOD2P__Health And Medical Administrative Services</th>\n",
       "      <th>FOD2P__Health And Medical Preparatory Programs</th>\n",
       "      <th>FOD2P__History</th>\n",
       "      <th>FOD2P__Hospitality Management</th>\n",
       "      <th>FOD2P__Human Resources And Personnel Management</th>\n",
       "      <th>FOD2P__Human Services And Community Organization</th>\n",
       "      <th>FOD2P__Humanities</th>\n",
       "      <th>FOD2P__Industrial And Manufacturing Engineering</th>\n",
       "      <th>FOD2P__Industrial And Organizational Psychology</th>\n",
       "      <th>FOD2P__Industrial Production Technologies</th>\n",
       "      <th>FOD2P__Information Sciences</th>\n",
       "      <th>FOD2P__Intercultural And International Studies</th>\n",
       "      <th>FOD2P__Interdisciplinary Social Sciences</th>\n",
       "      <th>FOD2P__International Business</th>\n",
       "      <th>FOD2P__International Relations</th>\n",
       "      <th>FOD2P__Journalism</th>\n",
       "      <th>FOD2P__Language And Drama Education</th>\n",
       "      <th>FOD2P__Liberal Arts</th>\n",
       "      <th>FOD2P__Library Science</th>\n",
       "      <th>FOD2P__Linguistics And Comparative Language And Literature</th>\n",
       "      <th>FOD2P__Management Information Systems And Statistics</th>\n",
       "      <th>FOD2P__Marketing And Marketing Research</th>\n",
       "      <th>FOD2P__Mass Media</th>\n",
       "      <th>FOD2P__Materials Engineering And Materials Science</th>\n",
       "      <th>FOD2P__Materials Science</th>\n",
       "      <th>FOD2P__Mathematics</th>\n",
       "      <th>FOD2P__Mathematics And Computer Science</th>\n",
       "      <th>FOD2P__Mechanical Engineering</th>\n",
       "      <th>FOD2P__Medical Assisting Services</th>\n",
       "      <th>FOD2P__Medical Technologies Technicians</th>\n",
       "      <th>FOD2P__Metallurgical Engineering</th>\n",
       "      <th>FOD2P__Microbiology</th>\n",
       "      <th>FOD2P__Miscellaneous Biology</th>\n",
       "      <th>FOD2P__Miscellaneous Business &amp; Medical Administration</th>\n",
       "      <th>FOD2P__Miscellaneous Education</th>\n",
       "      <th>FOD2P__Miscellaneous Engineering</th>\n",
       "      <th>FOD2P__Miscellaneous Engineering Technologies</th>\n",
       "      <th>FOD2P__Miscellaneous Fine Arts</th>\n",
       "      <th>FOD2P__Miscellaneous Health Medical Professions</th>\n",
       "      <th>FOD2P__Miscellaneous Psychology</th>\n",
       "      <th>FOD2P__Miscellaneous Social Sciences</th>\n",
       "      <th>FOD2P__Molecular Biology</th>\n",
       "      <th>FOD2P__Multi-Disciplinary Or General Science</th>\n",
       "      <th>FOD2P__Multi/Interdisciplinary Studies</th>\n",
       "      <th>FOD2P__Music</th>\n",
       "      <th>FOD2P__Natural Resources Management</th>\n",
       "      <th>FOD2P__Neuroscience</th>\n",
       "      <th>FOD2P__No major</th>\n",
       "      <th>FOD2P__Nursing</th>\n",
       "      <th>FOD2P__Nutrition Sciences</th>\n",
       "      <th>FOD2P__Oceanography</th>\n",
       "      <th>FOD2P__Operations Logistics And E-Commerce</th>\n",
       "      <th>FOD2P__Other Foreign Languages</th>\n",
       "      <th>FOD2P__Pharmacy Pharmaceutical Sciences And Administration</th>\n",
       "      <th>FOD2P__Philosophy And Religious Studies</th>\n",
       "      <th>FOD2P__Physical And Health Education Teaching</th>\n",
       "      <th>FOD2P__Physical Fitness Parks Recreation And Leisure</th>\n",
       "      <th>FOD2P__Physical Sciences</th>\n",
       "      <th>FOD2P__Physics</th>\n",
       "      <th>FOD2P__Physiology</th>\n",
       "      <th>FOD2P__Plant Science And Agronomy</th>\n",
       "      <th>FOD2P__Political Science And Government</th>\n",
       "      <th>FOD2P__Pre-Law And Legal Studies</th>\n",
       "      <th>FOD2P__Psychology</th>\n",
       "      <th>FOD2P__Public Administration</th>\n",
       "      <th>FOD2P__Public Policy</th>\n",
       "      <th>FOD2P__Science And Computer Teacher Education</th>\n",
       "      <th>FOD2P__Secondary Teacher Education</th>\n",
       "      <th>FOD2P__Social Science Or History Teacher Education</th>\n",
       "      <th>FOD2P__Social Work</th>\n",
       "      <th>FOD2P__Sociology</th>\n",
       "      <th>FOD2P__Soil Science</th>\n",
       "      <th>FOD2P__Special Needs Education</th>\n",
       "      <th>FOD2P__Statistics And Decision Science</th>\n",
       "      <th>FOD2P__Studio Arts</th>\n",
       "      <th>FOD2P__Theology And Religious Vocations</th>\n",
       "      <th>FOD2P__Treatment Therapy Professions</th>\n",
       "      <th>FOD2P__United States History</th>\n",
       "      <th>FOD2P__Visual And Performing Arts</th>\n",
       "      <th>FOD2P__Zoology</th>\n",
       "      <th>SCHL__1 or more years of college credit, no degree</th>\n",
       "      <th>SCHL__12th grade - no diploma</th>\n",
       "      <th>SCHL__Associate's degree</th>\n",
       "      <th>SCHL__Bachelor's degree</th>\n",
       "      <th>SCHL__Doctorate degree</th>\n",
       "      <th>SCHL__GED or alternative credential</th>\n",
       "      <th>SCHL__Grade 1</th>\n",
       "      <th>SCHL__Grade 10</th>\n",
       "      <th>SCHL__Grade 11</th>\n",
       "      <th>SCHL__Grade 2</th>\n",
       "      <th>SCHL__Grade 3</th>\n",
       "      <th>SCHL__Grade 4</th>\n",
       "      <th>SCHL__Grade 5</th>\n",
       "      <th>SCHL__Grade 6</th>\n",
       "      <th>SCHL__Grade 7</th>\n",
       "      <th>SCHL__Grade 8</th>\n",
       "      <th>SCHL__Grade 9</th>\n",
       "      <th>SCHL__Kindergarten</th>\n",
       "      <th>SCHL__Master's degree</th>\n",
       "      <th>SCHL__No schooling completed</th>\n",
       "      <th>SCHL__Nursery school, preschool</th>\n",
       "      <th>SCHL__Professional degree beyond a bachelor's degree</th>\n",
       "      <th>SCHL__Regular high school diploma</th>\n",
       "      <th>SCHL__Some college, but less than 1 year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74193</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7307</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58062</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34395</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28769</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SCHL_ord  FOD1P_MAJ__Agriculture, agriculture operations, and related sciences  FOD1P_MAJ__Architecture and related services  FOD1P_MAJ__Area, ethnic, cultural, gender, and group studies  FOD1P_MAJ__Biological and biomedical sciences  FOD1P_MAJ__Business, management, marketing, and related support services  FOD1P_MAJ__Communication, journalism, and related programs  FOD1P_MAJ__Communications technologies/technicians and support services  FOD1P_MAJ__Computer and information sciences and support services  FOD1P_MAJ__Construction trades  FOD1P_MAJ__Education  FOD1P_MAJ__Engineering  FOD1P_MAJ__Engineering technologies and engineering-related fields  FOD1P_MAJ__English language and literature/letters  FOD1P_MAJ__Family and consumer sciences/human sciences  FOD1P_MAJ__Foreign languages, literatures, and linguistics  FOD1P_MAJ__Health professions and related programs  FOD1P_MAJ__History  FOD1P_MAJ__Homeland security, law enforcement, firefighting and related protective services  \\\n",
       "74193        18                                                  0                                                                0                                                  0                                                         0                                                  0                                                                         0                                                           0                                                                        0                                               0                     0                       0                                                  0                                                                   0                                                   0                                                       0                                                           0                    0                                                  0                                             \n",
       "7307         18                                                  0                                                                0                                                  0                                                         0                                                  0                                                                         0                                                           0                                                                        0                                               0                     0                       0                                                  0                                                                   0                                                   0                                                       0                                                           0                    0                                                  0                                             \n",
       "58062        18                                                  0                                                                0                                                  0                                                         0                                                  0                                                                         0                                                           0                                                                        0                                               0                     0                       0                                                  0                                                                   0                                                   0                                                       0                                                           0                    0                                                  0                                             \n",
       "34395        21                                                  0                                                                0                                                  0                                                         1                                                  0                                                                         0                                                           0                                                                        0                                               0                     0                       0                                                  0                                                                   0                                                   0                                                       0                                                           0                    0                                                  0                                             \n",
       "28769        21                                                  0                                                                0                                                  0                                                         0                                                  0                                                                         0                                                           0                                                                        1                                               0                     0                       0                                                  0                                                                   0                                                   0                                                       0                                                           0                    0                                                  0                                             \n",
       "\n",
       "       FOD1P_MAJ__Legal professions and studies  FOD1P_MAJ__Liberal arts and sciences, general studies and humanities  FOD1P_MAJ__Library science  FOD1P_MAJ__Mathematics and statistics  FOD1P_MAJ__Mechanic and repair technologies/technicians  FOD1P_MAJ__Military science, leadership and operational art  FOD1P_MAJ__Multi/interdisciplinary studies  FOD1P_MAJ__Natural resources and conservation  FOD1P_MAJ__No major  FOD1P_MAJ__Parks, recreation, leisure, and fitness studies  FOD1P_MAJ__Personal and culinary services  FOD1P_MAJ__Philosophy and religious studies  FOD1P_MAJ__Physical sciences  FOD1P_MAJ__Psychology  FOD1P_MAJ__Public administration and social service professions  FOD1P_MAJ__Science technologies/technicians  FOD1P_MAJ__Social sciences  FOD1P_MAJ__Theology and religious vocations  FOD1P_MAJ__Transportation and materials moving  FOD1P_MAJ__Visual and performing arts  FOD1P__Accounting  FOD1P__Actuarial Science  FOD1P__Advertising And Public Relations  \\\n",
       "74193                                         0                                                  0                                              0                                      0                                                  0                                                        0                                                     0                                              0                    1                                                  0                                                   0                                            0                             0                      0                                                  0                                                          0                           0                                            0                                               0                                      0                  0                         0                                        0   \n",
       "7307                                          0                                                  0                                              0                                      0                                                  0                                                        0                                                     0                                              0                    1                                                  0                                                   0                                            0                             0                      0                                                  0                                                          0                           0                                            0                                               0                                      0                  0                         0                                        0   \n",
       "58062                                         0                                                  0                                              0                                      0                                                  0                                                        0                                                     0                                              0                    1                                                  0                                                   0                                            0                             0                      0                                                  0                                                          0                           0                                            0                                               0                                      0                  0                         0                                        0   \n",
       "34395                                         0                                                  0                                              0                                      0                                                  0                                                        0                                                     0                                              0                    0                                                  0                                                   0                                            0                             0                      0                                                  0                                                          0                           0                                            0                                               0                                      0                  0                         0                                        0   \n",
       "28769                                         0                                                  0                                              0                                      0                                                  0                                                        0                                                     0                                              0                    0                                                  0                                                   0                                            0                             0                      0                                                  0                                                          0                           0                                            0                                               0                                      0                  0                         0                                        0   \n",
       "\n",
       "       FOD1P__Aerospace Engineering  FOD1P__Agricultural Economics  FOD1P__Agriculture Production And Management  FOD1P__Animal Sciences  FOD1P__Anthropology And Archeology  FOD1P__Applied Mathematics  FOD1P__Architectural Engineering  FOD1P__Architecture  FOD1P__Area Ethnic And Civilization Studies  FOD1P__Art And Music Education  FOD1P__Art History And Criticism  FOD1P__Astronomy And Astrophysics  FOD1P__Atmospheric Sciences And Meteorology  FOD1P__Biochemical Sciences  FOD1P__Biological Engineering  FOD1P__Biology  FOD1P__Biomedical Engineering  FOD1P__Botany  FOD1P__Business Economics  FOD1P__Business Management And Administration  FOD1P__Chemical Engineering  FOD1P__Chemistry  FOD1P__Civil Engineering  FOD1P__Clinical Psychology  FOD1P__Cognitive Science And Biopsychology  FOD1P__Commercial Art And Graphic Design  FOD1P__Communication Disorders Sciences And Services  FOD1P__Communication Technologies  FOD1P__Communications  FOD1P__Community And Public Health  \\\n",
       "74193                             0                              0                                             0                       0                                   0                           0                                 0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0              0                          0                                              0                            0                 0                         0                           0                                           0                                         0                                                  0                                     0                      0                                   0   \n",
       "7307                              0                              0                                             0                       0                                   0                           0                                 0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0              0                          0                                              0                            0                 0                         0                           0                                           0                                         0                                                  0                                     0                      0                                   0   \n",
       "58062                             0                              0                                             0                       0                                   0                           0                                 0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0              0                          0                                              0                            0                 0                         0                           0                                           0                                         0                                                  0                                     0                      0                                   0   \n",
       "34395                             0                              0                                             0                       0                                   0                           0                                 0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               1                              0              0                          0                                              0                            0                 0                         0                           0                                           0                                         0                                                  0                                     0                      0                                   0   \n",
       "28769                             0                              0                                             0                       0                                   0                           0                                 0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0              0                          0                                              0                            0                 0                         0                           0                                           0                                         0                                                  0                                     0                      0                                   0   \n",
       "\n",
       "       FOD1P__Composition And Rhetoric  FOD1P__Computer Administration Management And Security  FOD1P__Computer And Information Systems  FOD1P__Computer Engineering  FOD1P__Computer Networking And Telecommunications  FOD1P__Computer Programming And Data Processing  FOD1P__Computer Science  FOD1P__Construction Services  FOD1P__Cosmetology Services And Culinary Arts  FOD1P__Counseling Psychology  FOD1P__Court Reporting  FOD1P__Criminal Justice And Fire Protection  FOD1P__Criminology  FOD1P__Drama And Theater Arts  FOD1P__Early Childhood Education  FOD1P__Ecology  FOD1P__Economics  FOD1P__Educational Administration And Supervision  FOD1P__Educational Psychology  FOD1P__Electrical Engineering  FOD1P__Electrical Engineering Technology  FOD1P__Electrical, Mechanical, And Precision Technologies And Production  FOD1P__Elementary Education  FOD1P__Engineering And Industrial Management  FOD1P__Engineering Mechanics Physics And Science  FOD1P__Engineering Technologies  \\\n",
       "74193                                0                                                  0                                             0                            0                                                  0                                                0                        0                             0                                              0                             0                       0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0                                             0                                                 0                                0   \n",
       "7307                                 0                                                  0                                             0                            0                                                  0                                                0                        0                             0                                              0                             0                       0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0                                             0                                                 0                                0   \n",
       "58062                                0                                                  0                                             0                            0                                                  0                                                0                        0                             0                                              0                             0                       0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0                                             0                                                 0                                0   \n",
       "34395                                0                                                  0                                             0                            0                                                  0                                                0                        0                             0                                              0                             0                       0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0                                             0                                                 0                                0   \n",
       "28769                                0                                                  0                                             1                            0                                                  0                                                0                        0                             0                                              0                             0                       0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0                                             0                                                 0                                0   \n",
       "\n",
       "       FOD1P__English Language And Literature  FOD1P__Environmental Engineering  FOD1P__Environmental Science  FOD1P__Family And Consumer Sciences  FOD1P__Film Video And Photographic Arts  FOD1P__Finance  FOD1P__Fine Arts  FOD1P__Food Science  FOD1P__Forestry  FOD1P__French German Latin And Other Common Foreign Language Studies  FOD1P__General Agriculture  FOD1P__General Business  FOD1P__General Education  FOD1P__General Engineering  FOD1P__General Medical And Health Services  FOD1P__General Social Sciences  FOD1P__Genetics  FOD1P__Geography  FOD1P__Geological And Geophysical Engineering  FOD1P__Geology And Earth Science  FOD1P__Geosciences  FOD1P__Health And Medical Administrative Services  FOD1P__Health And Medical Preparatory Programs  FOD1P__History  FOD1P__Hospitality Management  FOD1P__Human Resources And Personnel Management  FOD1P__Human Services And Community Organization  FOD1P__Humanities  FOD1P__Industrial And Manufacturing Engineering  \\\n",
       "74193                                       0                                 0                             0                                    0                                        0               0                 0                    0                0                                                  0                                              0                        0                         0                           0                                           0                               0                0                 0                                              0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0                                                0   \n",
       "7307                                        0                                 0                             0                                    0                                        0               0                 0                    0                0                                                  0                                              0                        0                         0                           0                                           0                               0                0                 0                                              0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0                                                0   \n",
       "58062                                       0                                 0                             0                                    0                                        0               0                 0                    0                0                                                  0                                              0                        0                         0                           0                                           0                               0                0                 0                                              0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0                                                0   \n",
       "34395                                       0                                 0                             0                                    0                                        0               0                 0                    0                0                                                  0                                              0                        0                         0                           0                                           0                               0                0                 0                                              0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0                                                0   \n",
       "28769                                       0                                 0                             0                                    0                                        0               0                 0                    0                0                                                  0                                              0                        0                         0                           0                                           0                               0                0                 0                                              0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0                                                0   \n",
       "\n",
       "       FOD1P__Industrial And Organizational Psychology  FOD1P__Industrial Production Technologies  FOD1P__Information Sciences  FOD1P__Intercultural And International Studies  FOD1P__Interdisciplinary Social Sciences  FOD1P__International Business  FOD1P__International Relations  FOD1P__Journalism  FOD1P__Language And Drama Education  FOD1P__Liberal Arts  FOD1P__Library Science  FOD1P__Linguistics And Comparative Language And Literature  FOD1P__Management Information Systems And Statistics  FOD1P__Marketing And Marketing Research  FOD1P__Mass Media  FOD1P__Materials Engineering And Materials Science  FOD1P__Materials Science  FOD1P__Mathematics  FOD1P__Mathematics And Computer Science  FOD1P__Mathematics Teacher Education  FOD1P__Mechanical Engineering  FOD1P__Mechanical Engineering Related Technologies  FOD1P__Medical Assisting Services  FOD1P__Medical Technologies Technicians  FOD1P__Metallurgical Engineering  FOD1P__Microbiology  FOD1P__Military Technologies  \\\n",
       "74193                                                0                                          0                            0                                               0                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                                     0                              0                                                  0                                   0                                        0                                 0                    0                             0   \n",
       "7307                                                 0                                          0                            0                                               0                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                                     0                              0                                                  0                                   0                                        0                                 0                    0                             0   \n",
       "58062                                                0                                          0                            0                                               0                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                                     0                              0                                                  0                                   0                                        0                                 0                    0                             0   \n",
       "34395                                                0                                          0                            0                                               0                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                                     0                              0                                                  0                                   0                                        0                                 0                    0                             0   \n",
       "28769                                                0                                          0                            0                                               0                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                                     0                              0                                                  0                                   0                                        0                                 0                    0                             0   \n",
       "\n",
       "       FOD1P__Mining And Mineral Engineering  FOD1P__Miscellaneous Agriculture  FOD1P__Miscellaneous Biology  FOD1P__Miscellaneous Business & Medical Administration  FOD1P__Miscellaneous Education  FOD1P__Miscellaneous Engineering  FOD1P__Miscellaneous Engineering Technologies  FOD1P__Miscellaneous Fine Arts  FOD1P__Miscellaneous Health Medical Professions  FOD1P__Miscellaneous Psychology  FOD1P__Miscellaneous Social Sciences  FOD1P__Molecular Biology  FOD1P__Multi-Disciplinary Or General Science  FOD1P__Multi/Interdisciplinary Studies  FOD1P__Music  FOD1P__Natural Resources Management  FOD1P__Naval Architecture And Marine Engineering  FOD1P__Neuroscience  FOD1P__No major  FOD1P__Nuclear Engineering  FOD1P__Nuclear, Industrial Radiology, And Biological Technologies  FOD1P__Nursing  FOD1P__Nutrition Sciences  FOD1P__Oceanography  FOD1P__Operations Logistics And E-Commerce  FOD1P__Other Foreign Languages  FOD1P__Petroleum Engineering  FOD1P__Pharmacology  \\\n",
       "74193                                      0                                 0                             0                                                  0                                    0                                 0                                              0                               0                                                0                                0                                     0                         0                                             0                                       0             0                                    0                                                 0                    0                1                           0                                                  0                               0                          0                    0                                           0                               0                             0                    0   \n",
       "7307                                       0                                 0                             0                                                  0                                    0                                 0                                              0                               0                                                0                                0                                     0                         0                                             0                                       0             0                                    0                                                 0                    0                1                           0                                                  0                               0                          0                    0                                           0                               0                             0                    0   \n",
       "58062                                      0                                 0                             0                                                  0                                    0                                 0                                              0                               0                                                0                                0                                     0                         0                                             0                                       0             0                                    0                                                 0                    0                1                           0                                                  0                               0                          0                    0                                           0                               0                             0                    0   \n",
       "34395                                      0                                 0                             0                                                  0                                    0                                 0                                              0                               0                                                0                                0                                     0                         0                                             0                                       0             0                                    0                                                 0                    0                0                           0                                                  0                               0                          0                    0                                           0                               0                             0                    0   \n",
       "28769                                      0                                 0                             0                                                  0                                    0                                 0                                              0                               0                                                0                                0                                     0                         0                                             0                                       0             0                                    0                                                 0                    0                0                           0                                                  0                               0                          0                    0                                           0                               0                             0                    0   \n",
       "\n",
       "       FOD1P__Pharmacy Pharmaceutical Sciences And Administration  FOD1P__Philosophy And Religious Studies  FOD1P__Physical And Health Education Teaching  FOD1P__Physical Fitness Parks Recreation And Leisure  FOD1P__Physical Sciences  FOD1P__Physics  FOD1P__Physiology  FOD1P__Plant Science And Agronomy  FOD1P__Political Science And Government  FOD1P__Pre-Law And Legal Studies  FOD1P__Psychology  FOD1P__Public Administration  FOD1P__Public Policy  FOD1P__School Student Counseling  FOD1P__Science And Computer Teacher Education  FOD1P__Secondary Teacher Education  FOD1P__Social Psychology  FOD1P__Social Science Or History Teacher Education  FOD1P__Social Work  FOD1P__Sociology  FOD1P__Soil Science  FOD1P__Special Needs Education  FOD1P__Statistics And Decision Science  FOD1P__Studio Arts  FOD1P__Teacher Education: Multiple Levels  FOD1P__Theology And Religious Vocations  FOD1P__Transportation Sciences And Technologies  FOD1P__Treatment Therapy Professions  FOD1P__United States History  \\\n",
       "74193                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                 0                                              0                                   0                         0                                                  0                    0                 0                    0                               0                                       0                   0                                          0                                        0                                                0                                     0                             0   \n",
       "7307                                                   0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                 0                                              0                                   0                         0                                                  0                    0                 0                    0                               0                                       0                   0                                          0                                        0                                                0                                     0                             0   \n",
       "58062                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                 0                                              0                                   0                         0                                                  0                    0                 0                    0                               0                                       0                   0                                          0                                        0                                                0                                     0                             0   \n",
       "34395                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                 0                                              0                                   0                         0                                                  0                    0                 0                    0                               0                                       0                   0                                          0                                        0                                                0                                     0                             0   \n",
       "28769                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                 0                                              0                                   0                         0                                                  0                    0                 0                    0                               0                                       0                   0                                          0                                        0                                                0                                     0                             0   \n",
       "\n",
       "       FOD1P__Visual And Performing Arts  FOD1P__Zoology  FOD2P__Accounting  FOD2P__Advertising And Public Relations  FOD2P__Aerospace Engineering  FOD2P__Agriculture Production And Management  FOD2P__Animal Sciences  FOD2P__Anthropology And Archeology  FOD2P__Applied Mathematics  FOD2P__Architecture  FOD2P__Area Ethnic And Civilization Studies  FOD2P__Art And Music Education  FOD2P__Art History And Criticism  FOD2P__Astronomy And Astrophysics  FOD2P__Atmospheric Sciences And Meteorology  FOD2P__Biochemical Sciences  FOD2P__Biological Engineering  FOD2P__Biology  FOD2P__Biomedical Engineering  FOD2P__Business Economics  FOD2P__Business Management And Administration  FOD2P__Chemistry  FOD2P__Civil Engineering  FOD2P__Clinical Psychology  FOD2P__Cognitive Science And Biopsychology  FOD2P__Commercial Art And Graphic Design  FOD2P__Communication Disorders Sciences And Services  FOD2P__Communication Technologies  FOD2P__Communications  FOD2P__Community And Public Health  \\\n",
       "74193                                  0               0                  0                                        0                             0                                             0                       0                                   0                           0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0                          0                                              0                 0                         0                           0                                           0                                         0                                                  0                                     0                      0                                   0   \n",
       "7307                                   0               0                  0                                        0                             0                                             0                       0                                   0                           0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0                          0                                              0                 0                         0                           0                                           0                                         0                                                  0                                     0                      0                                   0   \n",
       "58062                                  0               0                  0                                        0                             0                                             0                       0                                   0                           0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0                          0                                              0                 0                         0                           0                                           0                                         0                                                  0                                     0                      0                                   0   \n",
       "34395                                  0               0                  0                                        0                             0                                             0                       0                                   0                           0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0                          0                                              0                 0                         0                           0                                           0                                         0                                                  0                                     0                      0                                   0   \n",
       "28769                                  0               0                  0                                        0                             0                                             0                       0                                   0                           0                    0                                            0                               0                                 0                                  0                                            0                            0                              0               0                              0                          0                                              0                 0                         0                           0                                           0                                         0                                                  0                                     0                      0                                   0   \n",
       "\n",
       "       FOD2P__Composition And Rhetoric  FOD2P__Computer Administration Management And Security  FOD2P__Computer And Information Systems  FOD2P__Computer Engineering  FOD2P__Computer Networking And Telecommunications  FOD2P__Computer Programming And Data Processing  FOD2P__Computer Science  FOD2P__Cosmetology Services And Culinary Arts  FOD2P__Counseling Psychology  FOD2P__Criminal Justice And Fire Protection  FOD2P__Criminology  FOD2P__Drama And Theater Arts  FOD2P__Early Childhood Education  FOD2P__Ecology  FOD2P__Economics  FOD2P__Educational Administration And Supervision  FOD2P__Educational Psychology  FOD2P__Electrical Engineering  FOD2P__Electrical Engineering Technology  FOD2P__Electrical, Mechanical, And Precision Technologies And Production  FOD2P__Elementary Education  FOD2P__Engineering And Industrial Management  FOD2P__Engineering Mechanics Physics And Science  FOD2P__Engineering Technologies  FOD2P__English Language And Literature  FOD2P__Environmental Engineering  \\\n",
       "74193                                0                                                  0                                             0                            0                                                  0                                                0                        0                                              0                             0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0                                             0                                                 0                                0                                       0                                 0   \n",
       "7307                                 0                                                  0                                             0                            0                                                  0                                                0                        0                                              0                             0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0                                             0                                                 0                                0                                       0                                 0   \n",
       "58062                                0                                                  0                                             0                            0                                                  0                                                0                        0                                              0                             0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0                                             0                                                 0                                0                                       0                                 0   \n",
       "34395                                0                                                  0                                             0                            0                                                  0                                                0                        0                                              0                             0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0                                             0                                                 0                                0                                       0                                 0   \n",
       "28769                                0                                                  0                                             0                            0                                                  0                                                0                        0                                              0                             0                                            0                   0                              0                                 0               0                 0                                                  0                              0                              0                                         0                                                  0                                                   0                                             0                                                 0                                0                                       0                                 0   \n",
       "\n",
       "       FOD2P__Environmental Science  FOD2P__Family And Consumer Sciences  FOD2P__Film Video And Photographic Arts  FOD2P__Finance  FOD2P__Fine Arts  FOD2P__Food Science  FOD2P__Forestry  FOD2P__French German Latin And Other Common Foreign Language Studies  FOD2P__General Business  FOD2P__General Education  FOD2P__General Engineering  FOD2P__General Medical And Health Services  FOD2P__General Social Sciences  FOD2P__Genetics  FOD2P__Geography  FOD2P__Geology And Earth Science  FOD2P__Geosciences  FOD2P__Health And Medical Administrative Services  FOD2P__Health And Medical Preparatory Programs  FOD2P__History  FOD2P__Hospitality Management  FOD2P__Human Resources And Personnel Management  FOD2P__Human Services And Community Organization  FOD2P__Humanities  FOD2P__Industrial And Manufacturing Engineering  FOD2P__Industrial And Organizational Psychology  FOD2P__Industrial Production Technologies  FOD2P__Information Sciences  FOD2P__Intercultural And International Studies  \\\n",
       "74193                             0                                    0                                        0               0                 0                    0                0                                                  0                                           0                         0                           0                                           0                               0                0                 0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0                                                0                                                0                                          0                            0                                               0   \n",
       "7307                              0                                    0                                        0               0                 0                    0                0                                                  0                                           0                         0                           0                                           0                               0                0                 0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0                                                0                                                0                                          0                            0                                               0   \n",
       "58062                             0                                    0                                        0               0                 0                    0                0                                                  0                                           0                         0                           0                                           0                               0                0                 0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0                                                0                                                0                                          0                            0                                               0   \n",
       "34395                             0                                    0                                        0               0                 0                    0                0                                                  0                                           0                         0                           0                                           0                               0                0                 0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0                                                0                                                0                                          0                            0                                               0   \n",
       "28769                             0                                    0                                        0               0                 0                    0                0                                                  0                                           0                         0                           0                                           0                               0                0                 0                                 0                   0                                                  0                                               0               0                              0                                                0                                                 0                  0                                                0                                                0                                          0                            0                                               0   \n",
       "\n",
       "       FOD2P__Interdisciplinary Social Sciences  FOD2P__International Business  FOD2P__International Relations  FOD2P__Journalism  FOD2P__Language And Drama Education  FOD2P__Liberal Arts  FOD2P__Library Science  FOD2P__Linguistics And Comparative Language And Literature  FOD2P__Management Information Systems And Statistics  FOD2P__Marketing And Marketing Research  FOD2P__Mass Media  FOD2P__Materials Engineering And Materials Science  FOD2P__Materials Science  FOD2P__Mathematics  FOD2P__Mathematics And Computer Science  FOD2P__Mechanical Engineering  FOD2P__Medical Assisting Services  FOD2P__Medical Technologies Technicians  FOD2P__Metallurgical Engineering  FOD2P__Microbiology  FOD2P__Miscellaneous Biology  FOD2P__Miscellaneous Business & Medical Administration  FOD2P__Miscellaneous Education  FOD2P__Miscellaneous Engineering  FOD2P__Miscellaneous Engineering Technologies  FOD2P__Miscellaneous Fine Arts  FOD2P__Miscellaneous Health Medical Professions  \\\n",
       "74193                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                              0                                  0                                        0                                 0                    0                             0                                                  0                                    0                                 0                                              0                               0                                                0   \n",
       "7307                                          0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                              0                                  0                                        0                                 0                    0                             0                                                  0                                    0                                 0                                              0                               0                                                0   \n",
       "58062                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                              0                                  0                                        0                                 0                    0                             0                                                  0                                    0                                 0                                              0                               0                                                0   \n",
       "34395                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                              0                                  0                                        0                                 0                    0                             0                                                  0                                    0                                 0                                              0                               0                                                0   \n",
       "28769                                         0                              0                               0                  0                                    0                    0                       0                                                  0                                                           0                                           0                  0                                                  0                          0                   0                                        0                              0                                  0                                        0                                 0                    0                             0                                                  0                                    0                                 0                                              0                               0                                                0   \n",
       "\n",
       "       FOD2P__Miscellaneous Psychology  FOD2P__Miscellaneous Social Sciences  FOD2P__Molecular Biology  FOD2P__Multi-Disciplinary Or General Science  FOD2P__Multi/Interdisciplinary Studies  FOD2P__Music  FOD2P__Natural Resources Management  FOD2P__Neuroscience  FOD2P__No major  FOD2P__Nursing  FOD2P__Nutrition Sciences  FOD2P__Oceanography  FOD2P__Operations Logistics And E-Commerce  FOD2P__Other Foreign Languages  FOD2P__Pharmacy Pharmaceutical Sciences And Administration  FOD2P__Philosophy And Religious Studies  FOD2P__Physical And Health Education Teaching  FOD2P__Physical Fitness Parks Recreation And Leisure  FOD2P__Physical Sciences  FOD2P__Physics  FOD2P__Physiology  FOD2P__Plant Science And Agronomy  FOD2P__Political Science And Government  FOD2P__Pre-Law And Legal Studies  FOD2P__Psychology  FOD2P__Public Administration  FOD2P__Public Policy  FOD2P__Science And Computer Teacher Education  FOD2P__Secondary Teacher Education  FOD2P__Social Science Or History Teacher Education  \\\n",
       "74193                                0                                     0                         0                                             0                                       0             0                                    0                    0                1               0                          0                    0                                           0                               0                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                              0                                   0                                                  0    \n",
       "7307                                 0                                     0                         0                                             0                                       0             0                                    0                    0                1               0                          0                    0                                           0                               0                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                              0                                   0                                                  0    \n",
       "58062                                0                                     0                         0                                             0                                       0             0                                    0                    0                1               0                          0                    0                                           0                               0                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                              0                                   0                                                  0    \n",
       "34395                                0                                     0                         0                                             0                                       0             0                                    0                    0                1               0                          0                    0                                           0                               0                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                              0                                   0                                                  0    \n",
       "28769                                0                                     0                         0                                             0                                       0             0                                    0                    0                1               0                          0                    0                                           0                               0                                                  0                                                 0                                              0                                                  0                            0               0                  0                                  0                                        0                                 0                  0                             0                     0                                              0                                   0                                                  0    \n",
       "\n",
       "       FOD2P__Social Work  FOD2P__Sociology  FOD2P__Soil Science  FOD2P__Special Needs Education  FOD2P__Statistics And Decision Science  FOD2P__Studio Arts  FOD2P__Theology And Religious Vocations  FOD2P__Treatment Therapy Professions  FOD2P__United States History  FOD2P__Visual And Performing Arts  FOD2P__Zoology  SCHL__1 or more years of college credit, no degree  SCHL__12th grade - no diploma  SCHL__Associate's degree  SCHL__Bachelor's degree  SCHL__Doctorate degree  SCHL__GED or alternative credential  SCHL__Grade 1  SCHL__Grade 10  SCHL__Grade 11  SCHL__Grade 2  SCHL__Grade 3  SCHL__Grade 4  SCHL__Grade 5  SCHL__Grade 6  SCHL__Grade 7  SCHL__Grade 8  SCHL__Grade 9  SCHL__Kindergarten  SCHL__Master's degree  SCHL__No schooling completed  SCHL__Nursery school, preschool  SCHL__Professional degree beyond a bachelor's degree  SCHL__Regular high school diploma  SCHL__Some college, but less than 1 year  \n",
       "74193                   0                 0                    0                               0                                       0                   0                                        0                                     0                             0                                  0               0                                                  0                               0                         0                        0                       0                                    0              0               0               0              0              0              0              0              0              0              0              0                   0                      0                             0                                0                                                  0                                     0                                         1  \n",
       "7307                    0                 0                    0                               0                                       0                   0                                        0                                     0                             0                                  0               0                                                  0                               0                         0                        0                       0                                    0              0               0               0              0              0              0              0              0              0              0              0                   0                      0                             0                                0                                                  0                                     0                                         1  \n",
       "58062                   0                 0                    0                               0                                       0                   0                                        0                                     0                             0                                  0               0                                                  0                               0                         0                        0                       0                                    0              0               0               0              0              0              0              0              0              0              0              0                   0                      0                             0                                0                                                  0                                     0                                         1  \n",
       "34395                   0                 0                    0                               0                                       0                   0                                        0                                     0                             0                                  0               0                                                  0                               0                         0                        1                       0                                    0              0               0               0              0              0              0              0              0              0              0              0                   0                      0                             0                                0                                                  0                                     0                                         0  \n",
       "28769                   0                 0                    0                               0                                       0                   0                                        0                                     0                             0                                  0               0                                                  0                               0                         0                        1                       0                                    0              0               0               0              0              0              0              0              0              0              0              0                   0                      0                             0                                0                                                  0                                     0                                         0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54184,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model pipelines\n",
    "#-----------------------------------\n",
    "#-------------linear\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_lr_l2 = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_sgd = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('clf', SGDClassifier(random_state=42))])\n",
    "\n",
    "\n",
    "#-------------trees\n",
    "pipe_dt = Pipeline([('clf', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "pipe_rf = Pipeline([('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_rf_scl = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_gb = Pipeline([('clf', GradientBoostingClassifier(random_state=42))])\n",
    "\n",
    "\n",
    "#-------------SVM\n",
    "pipe_svm = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('clf', SVC(random_state=42))])\n",
    "\n",
    "\n",
    "#-------------KNN\n",
    "pipe_knn = Pipeline([('clf', KNeighborsClassifier())])\n",
    "\n",
    "pipe_knn_scl = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('clf', KNeighborsClassifier())])\n",
    "\n",
    "#-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# grid search params\n",
    "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range_fl = [1.0, 0.5, 0.1]\n",
    "max_depth = [10,100,1000,10000]\n",
    "alpha_range = [.1, .001, .00001, .000001]\n",
    "gamma_range = [.1, 1, 10]\n",
    "\n",
    "#-------------linear\n",
    "grid_params_lr = [{'clf__penalty': ['l1'],\n",
    "\t\t'clf__C': param_range_fl,\n",
    "\t\t'clf__solver': ['liblinear', ],  #,'saga'\n",
    "        #'clf__multi_class': ['ovr', 'multinomial', 'auto'],\n",
    "        'clf__class_weight': [None, 'balanced']}] \n",
    "\n",
    "grid_params_lr_l2 = [{'clf__penalty': ['l2'],\n",
    "\t\t'clf__C': param_range_fl,\n",
    "\t\t'clf__solver': ['newton-cg', 'lbfgs', 'liblinear'],  #, 'sag'\n",
    "        #'clf__multi_class': ['ovr', 'multinomial', 'auto'],\n",
    "        'clf__class_weight': [None, 'balanced']}]\n",
    "\n",
    "grid_params_sgd = [{'clf__loss': ['hinge', 'log', 'perceptron'],\n",
    "\t\t'clf__alpha': alpha_range,\n",
    "\t\t'clf__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'clf__class_weight': [None, 'balanced']}] \n",
    "\n",
    "#-------------trees\n",
    "grid_params_dt = [{'clf__criterion': ['gini', 'entropy'],\n",
    "\t\t'clf__min_samples_leaf': param_range,\n",
    "\t\t'clf__max_depth': max_depth,\n",
    "\t\t'clf__min_samples_split': param_range[1:],\n",
    "        'clf__class_weight': [None, 'balanced']}]\n",
    "\n",
    "grid_params_rf = [{'clf__criterion': ['gini', 'entropy'],\n",
    "\t\t'clf__min_samples_leaf': param_range,\n",
    "\t\t'clf__max_depth': max_depth,\n",
    "\t\t'clf__min_samples_split': param_range[1:],\n",
    "        'clf__class_weight': [None, 'balanced', 'balanced_subsample']}]\n",
    "\n",
    "grid_params_gb = [{'clf__loss': ['deviance', 'exponential'],\n",
    "\t\t'clf__learning_rate': alpha_range,\n",
    "\t\t'clf__n_estimators': max_depth,\n",
    "\t\t'clf__subsample': param_range_fl}]\n",
    "\n",
    "#-------------SVM\n",
    "grid_params_svm = [{'clf__kernel': ['linear', 'rbf', 'poly'],\n",
    "        'clf__degree': param_range[1:],\n",
    "        'clf__gamma': gamma_range,\n",
    "        'clf__C': gamma_range,\n",
    "        'clf__class_weight': [None, 'balanced']}]\n",
    "\n",
    "#-------------KNN\n",
    "grid_params_knn = [{'clf__n_neighbors': param_range}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct grid searches\n",
    "jobs = -1\n",
    "verbose = 10\n",
    "\n",
    "#-------------linear\n",
    "gs_lr = GridSearchCV(estimator=pipe_lr,\n",
    "\t\t\tparam_grid=grid_params_lr,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10,\n",
    "            n_jobs=jobs,\n",
    "            verbose=verbose) \n",
    "\n",
    "gs_lr_l2 = GridSearchCV(estimator=pipe_lr_l2,\n",
    "\t\t\tparam_grid=grid_params_lr_l2,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10,\n",
    "            n_jobs=jobs,\n",
    "            verbose=verbose)\n",
    "\n",
    "gs_sgd = GridSearchCV(estimator=pipe_sgd,\n",
    "\t\t\tparam_grid=grid_params_sgd,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10,\n",
    "            verbose=verbose)\n",
    "\n",
    "    \n",
    "#-------------trees    \n",
    "gs_dt = GridSearchCV(estimator=pipe_rf,\n",
    "\t\t\tparam_grid=grid_params_dt,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10, \n",
    "\t\t\tn_jobs=jobs,\n",
    "            verbose=verbose)\n",
    "\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "\t\t\tparam_grid=grid_params_rf,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10, \n",
    "\t\t\tn_jobs=jobs,\n",
    "            verbose=verbose)\n",
    "\n",
    "gs_rf_scl = GridSearchCV(estimator=pipe_rf_scl,\n",
    "\t\t\tparam_grid=grid_params_rf,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10, \n",
    "\t\t\tn_jobs=jobs,\n",
    "            verbose=verbose)\n",
    "\n",
    "gs_gb = GridSearchCV(estimator=pipe_gb,\n",
    "\t\t\tparam_grid=grid_params_gb,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10, \n",
    "            verbose=verbose)\n",
    "\n",
    "#-------------SVM\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "\t\t\tparam_grid=grid_params_svm,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10,\n",
    "\t\t\tn_jobs=jobs,\n",
    "            verbose=verbose)\n",
    "\n",
    "#-------------KNN\n",
    "gs_knn = GridSearchCV(estimator=pipe_knn,\n",
    "\t\t\tparam_grid=grid_params_knn,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10,\n",
    "\t\t\tn_jobs=jobs,\n",
    "            verbose=verbose)\n",
    "\n",
    "gs_knn_scl = GridSearchCV(estimator=pipe_knn_scl,\n",
    "\t\t\tparam_grid=grid_params_knn,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10,\n",
    "\t\t\tn_jobs=jobs,\n",
    "            verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Logistic Regression w/ L1\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9671526111828751, total=32.1min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9682598265362613, total=33.0min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9673250876869116, total=33.4min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9686231081579919, total=33.7min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9667774086378738, total=36.1min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9680752906440303, total=36.8min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9697361136741096, total=36.9min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9695515777818786, total=39.7min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9658482554919697, total=39.9min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8551393245986343, total=44.3min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9664144676139509, total=47.7min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.862705296180107, total=53.3min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9697361136741096, total=17.0min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9664144676139509, total=20.2min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9695515777818786, total=20.0min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8593836501199483, total=40.6min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9671526111828751, total=20.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9680752906440303, total=21.5min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8691157467232785, total=43.5min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9682598265362613, total=18.5min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8558508674787745, total=47.0min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.861916189772937, total=43.7min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9669619785898855, total=20.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8695090439276486, total=54.9min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8549547887064035, total=58.0min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8643661192101862, total=59.2min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9686231081579919, total=21.8min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9658482554919697, total=23.0min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9671404836625437, total=19.6min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9697361136741096, total= 2.9min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8466506735560066, total=69.7min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9662299317217199, total= 3.9min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8551393245986343, total=21.9min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9697361136741096, total= 4.1min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9680752906440303, total= 2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.862705296180107, total=30.1min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9671526111828751, total= 5.8min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9682598265362613, total= 4.3min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9673311184939092, total= 4.2min\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9688076781100037, total= 3.6min\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9660328595163374, total= 4.0min\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8630743679645692, total= 7.3min\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.861916189772937, total=23.7min\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8691157467232785, total=25.9min\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8558508674787745, total=29.1min\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8549547887064035, total=30.8min\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8654733345635726, total=39.3min\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8597527219044104, total= 8.3min\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l1, clf__solver=liblinear, score=0.9673250876869116, total=11.6min\n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8466506735560066, total=37.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  60 | elapsed: 125.0min remaining: 25.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8556929322753275, total=12.0min\n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8593836501199483, total=43.6min\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8567737172388336, total= 6.7min\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8553238604908655, total= 8.1min\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8654733345635726, total= 9.6min\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8693244739756367, total= 6.7min\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8488651042627791, total= 9.2min\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8617315857485692, total= 6.3min\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8700387668451173, total= 7.0min\n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l1, clf__solver=liblinear, score=0.8695090439276486, total=37.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 130.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 0.1, 'clf__class_weight': None, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "Best training f1: 0.968\n",
      "Test set f1 score for best params: 0.398 \n",
      "\n",
      "Estimator: LogisticRegression w/ L2\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9697361136741096, total=  16.1s\n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9664144676139509, total=  16.0s\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9695515777818786, total=  30.2s\n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9671526111828751, total=  30.4s\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9682598265362613, total= 1.7min\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9686231081579919, total= 1.7min\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9680752906440303, total= 1.7min\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9680752906440303, total=  47.9s\n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9664144676139509, total= 1.8min\n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9682598265362613, total=  47.7s\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9695515777818786, total= 1.8min\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9673250876869116, total= 1.8min\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9667774086378738, total= 1.8min\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9658482554919697, total= 1.8min\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9671526111828751, total= 1.8min\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9697361136741096, total= 1.9min\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9667774086378738, total=  12.0s\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9686231081579919, total=  12.1s\n",
      "[CV] clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9658482554919697, total=  11.9s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9673250876869116, total=  11.7s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8551393245986343, total=  28.1s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.862889832072338, total=  29.1s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8593836501199483, total=  27.9s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8645506551024175, total=  27.4s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.966592838685862, total= 1.2min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9697361136741096, total= 1.5min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9682598265362613, total= 1.5min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9680752906440303, total= 1.6min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8466506735560066, total=  29.7s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9671526111828751, total= 1.7min\n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9695515777818786, total= 1.7min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8553238604908655, total=  31.8s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9664144676139509, total= 1.7min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9686231081579919, total= 1.7min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8558508674787745, total=  31.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9673250876869116, total= 1.7min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9658482554919697, total= 1.7min\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.862889832072338, total=  10.9s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8593836501199483, total=  16.7s\n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8551393245986343, total=  17.0s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8645506551024175, total=  17.2s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8466506735560066, total=  15.4s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8553238604908655, total=  21.2s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8558508674787745, total=  18.0s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8621007937973048, total=  16.5s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8667404946474715, total=  19.8s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8693003507476463, total=  20.6s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8667404946474715, total=  55.1s\n",
      "[CV] clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  4.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8693003507476463, total=  55.8s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8621007937973048, total=  54.0s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9664144676139509, total=  24.7s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9697361136741096, total=  29.9s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8693003507476463, total=  54.2s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8551393245986343, total= 1.2min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.862889832072338, total= 1.2min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8593836501199483, total= 1.2min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8466506735560066, total= 1.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8553238604908655, total= 1.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8667404946474715, total= 1.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9695515777818786, total=  31.9s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8621007937973048, total= 1.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9697361136741096, total=  20.1s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9671526111828751, total=  43.4s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8558508674787745, total= 1.6min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9664144676139509, total=  24.3s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=1.0, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8645506551024175, total= 2.0min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9695515777818786, total=  25.4s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9671526111828751, total=  29.6s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9682598265362613, total= 1.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9680752906440303, total=  30.8s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9682598265362613, total=  32.1s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9680752906440303, total= 1.3min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9686231081579919, total= 1.2min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9667774086378738, total= 1.3min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9667774086378738, total=  31.1s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9686231081579919, total=  29.5s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9658482554919697, total=  28.4s\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9658482554919697, total= 1.3min\n",
      "[CV] clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9673250876869116, total= 1.3min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9673250876869116, total=  21.2s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.862889832072338, total=  24.2s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8551393245986343, total=  31.0s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8593836501199483, total=  29.5s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9697361136741096, total= 1.3min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9680752906440303, total= 1.2min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.966592838685862, total= 1.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8645506551024175, total=  29.0s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9664144676139509, total= 1.3min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9695515777818786, total= 1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9686231081579919, total= 1.1min\n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9682598265362613, total= 1.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9671526111828751, total= 1.2min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9658482554919697, total= 1.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9673250876869116, total= 1.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.862889832072338, total=  13.2s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8551393245986343, total=  14.6s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8593836501199483, total=  15.6s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8645506551024175, total=  18.5s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8466506735560066, total=  22.8s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8553238604908655, total=  23.5s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8558508674787745, total=  19.4s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8667404946474715, total=  21.4s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8466506735560066, total=  50.5s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8693003507476463, total=  25.9s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8621007937973048, total=  23.8s\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8558508674787745, total= 1.0min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8553238604908655, total= 1.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8667404946474715, total= 1.1min\n",
      "[CV] clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8621007937973048, total= 1.1min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8693003507476463, total= 1.1min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9664144676139509, total=  19.4s\n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9697361136741096, total=  20.0s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9695515777818786, total=  20.1s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9671526111828751, total=  20.2s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8593836501199483, total= 1.1min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.862889832072338, total= 1.4min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8553238604908655, total= 1.1min\n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8466506735560066, total= 1.1min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8645506551024175, total= 1.2min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8551393245986343, total= 1.4min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8667404946474715, total=  57.8s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8693003507476463, total= 1.0min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8621007937973048, total= 1.0min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9697361136741096, total=  11.0s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.5, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8558508674787745, total= 1.4min\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9664144676139509, total=  19.4s\n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9682598265362613, total=  33.3s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9680752906440303, total=  34.5s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9695515777818786, total=  21.0s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9671526111828751, total=  21.9s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9667774086378738, total=  40.6s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9680752906440303, total=  22.1s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9682598265362613, total=  20.8s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9667774086378738, total=  20.0s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9658482554919697, total=  20.4s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9686231081579919, total=  20.9s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=lbfgs, score=0.9673250876869116, total=  20.5s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9686231081579919, total=  52.1s\n",
      "[CV] clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 10.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9673250876869116, total=  51.9s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.9658482554919697, total=  52.0s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.862889832072338, total=  23.8s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8551393245986343, total=  24.4s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9697361136741096, total=  52.8s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9664144676139509, total=  49.8s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9671526111828751, total=  49.1s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9695515777818786, total=  49.9s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9680752906440303, total=  48.3s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9682598265362613, total=  40.7s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9686231081579919, total=  40.5s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9658482554919697, total=  41.2s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.9673250876869116, total=  41.1s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8645506551024175, total=  31.6s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8593836501199483, total=  32.5s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.862889832072338, total=  16.5s\n",
      "[CV]  clf__C=0.1, clf__class_weight=None, clf__penalty=l2, clf__solver=liblinear, score=0.966592838685862, total=  59.5s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8551393245986343, total=  19.0s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8593836501199483, total=  18.4s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8466506735560066, total=  16.9s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8558508674787745, total=  18.9s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8645506551024175, total=  19.6s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8553238604908655, total=  19.8s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8695090439276486, total=  21.8s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8466506735560066, total=  53.9s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8693003507476463, total=  22.8s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8553238604908655, total=  58.5s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8695090439276486, total=  57.6s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8693003507476463, total=  57.7s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8558508674787745, total=  60.0s\n",
      "[CV] clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear \n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs, score=0.8621007937973048, total=  11.8s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=newton-cg, score=0.8621007937973048, total=  59.1s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8553238604908655, total=  32.7s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8693003507476463, total=  29.7s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8593836501199483, total=  38.3s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8645506551024175, total=  36.7s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8466506735560066, total=  36.0s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.862889832072338, total=  39.7s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8551393245986343, total=  40.4s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8667404946474715, total=  32.3s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8621007937973048, total=  30.8s\n",
      "[CV]  clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear, score=0.8558508674787745, total=  33.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 12.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 1.0, 'clf__class_weight': None, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}\n",
      "Best training f1: 0.968\n",
      "Test set f1 score for best params: 0.404 \n",
      "\n",
      "Estimator: SGDClassifier\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9640155010149474, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9640155010149474, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.8s remaining:    0.0s\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9640155010149474, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.1s remaining:    0.0s\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9640155010149474, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.5s remaining:    0.0s\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9640155010149474, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9640155010149474, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9641934293097084, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9641934293097084, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9649252353701311, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9643714232970279, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.966599003506182, total=   1.0s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9629082856615612, total=   1.0s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9675216829673371, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9654917881527957, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9649381804761026, total=   1.0s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9649381804761026, total=   1.0s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9638242894056848, total=   1.0s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9641934293097084, total=   1.0s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9658482554919697, total=   1.0s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9643714232970279, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.966783539398413, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.9640155010149474, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.9640155010149474, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.9640155010149474, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.9640155010149474, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.9640155010149474, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.9641934293097084, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.9641934293097084, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.9641868192726601, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.9641868192726601, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1, score=0.9640155010149474, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1, score=0.9640155010149474, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1, score=0.9640155010149474, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1, score=0.9640155010149474, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1, score=0.9640155010149474, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1, score=0.9640155010149474, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1, score=0.9641934293097084, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1, score=0.9641934293097084, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1, score=0.9649252353701311, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l1, score=0.9643714232970279, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2, score=0.9649381804761026, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2, score=0.9630928215537922, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2, score=0.9649381804761026, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2, score=0.9640155010149474, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2, score=0.9638309651227164, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2, score=0.9642000369071785, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2, score=0.9638242894056848, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2, score=0.9643779992617202, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2, score=0.9641868192726601, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=l2, score=0.9640022152482924, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet, score=0.9640155010149474, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet, score=0.9640155010149474, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet, score=0.9640155010149474, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet, score=0.9640155010149474, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet, score=0.9640155010149474, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet, score=0.9640155010149474, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet, score=0.9641934293097084, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet, score=0.9641934293097084, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet, score=0.9641868192726601, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=log, clf__penalty=elasticnet, score=0.9641868192726601, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1, score=0.9640155010149474, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1, score=0.9640155010149474, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1, score=0.9640155010149474, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1, score=0.9640155010149474, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1, score=0.9640155010149474, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1, score=0.9640155010149474, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1, score=0.9641934293097084, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1, score=0.9641934293097084, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1, score=0.9649252353701311, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l1, score=0.9643714232970279, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2, score=0.9680752906440303, total=   1.0s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2, score=0.9638309651227164, total=   1.0s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2, score=0.9680752906440303, total=   1.0s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2, score=0.9651227163683337, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2, score=0.9654917881527957, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2, score=0.9656763240450268, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2, score=0.9658545588778147, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2, score=0.9669619785898855, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2, score=0.9638176112239247, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=l2, score=0.9634484031751891, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9642000369071785, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9671526111828751, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9673371470751061, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9658608599372578, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9653072522605647, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9640155010149474, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9653008490217793, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet, score=0.966592838685862, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9641868192726601, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=None, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9640022152482924, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1, score=0.7027126776157963, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1, score=0.6999446392323306, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1, score=0.7034508211847205, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1, score=0.7078796825982654, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1, score=0.6929322753275512, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1, score=0.7082487543827274, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1, score=0.7019195275009229, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1, score=0.7142857142857143, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1, score=0.9185896252538306, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l1, score=0.9165589809857855, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2, score=0.8568001476287138, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2, score=0.8411145967890754, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2, score=0.8542166451374792, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2, score=0.858091898874331, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2, score=0.8409300608968444, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2, score=0.857722827089869, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2, score=0.8530823181985973, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2, score=0.8624953857511997, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2, score=0.8617315857485692, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=l2, score=0.8569318811150083, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet, score=0.8765454880974349, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet, score=0.8684259088392693, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet, score=0.8689795165159624, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet, score=0.8992434028418528, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet, score=0.7296549178815279, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet, score=0.890939287691456, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet, score=0.8798449612403101, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet, score=0.8929494278331488, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet, score=0.9208048735462433, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=hinge, clf__penalty=elasticnet, score=0.7592763522244784, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1, score=0.9501753090976195, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1, score=0.9483299501753091, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1, score=0.7034508211847205, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1, score=0.7078796825982654, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1, score=0.6885034139140063, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1, score=0.7032662852924894, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1, score=0.7015503875968992, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1, score=0.7141011443337025, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1, score=0.9185896252538306, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l1, score=0.9185896252538306, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2, score=0.8564310758442517, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2, score=0.8403764532201513, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2, score=0.8514486067540137, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2, score=0.8615980808267208, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2, score=0.8411145967890754, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2, score=0.8542166451374792, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2, score=0.8508674787744556, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2, score=0.8610188261351052, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2, score=0.8676389145283369, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=l2, score=0.8609931696510984, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet, score=0.720243587377745, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet, score=0.7466322199667835, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet, score=0.7235652334379037, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet, score=0.7270714153902934, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet, score=0.6995755674478686, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet, score=0.7261487359291382, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet, score=0.7275747508305648, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet, score=0.7141011443337025, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet, score=0.7325087686911574, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=log, clf__penalty=elasticnet, score=0.7219863393021967, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1, score=0.9510979885587747, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1, score=0.9483299501753091, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1, score=0.9612474626314819, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1, score=0.961985606200406, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1, score=0.6929322753275512, total=   1.5s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1, score=0.7082487543827274, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1, score=0.7015503875968992, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1, score=0.7141011443337025, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1, score=0.9185896252538306, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l1, score=0.040059073287797675, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2, score=0.6237313157409116, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2, score=0.6200405978962908, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2, score=0.6283447130466876, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2, score=0.5958663960140247, total=   1.1s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2, score=0.5862705296180107, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2, score=0.6268684259088393, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2, score=0.8076781100036914, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2, score=0.6096345514950167, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2, score=0.783644083441019, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=l2, score=0.7865977478309027, total=   1.2s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9494371655286953, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9608783908470198, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet, score=0.6423694408562466, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9586639601402472, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet, score=0.42646244694593105, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet, score=0.9474072707141539, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet, score=0.7015503875968992, total=   1.3s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet, score=0.7781469176818014, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet, score=0.7083256414989847, total=   1.4s\n",
      "[CV] clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.1, clf__class_weight=balanced, clf__loss=perceptron, clf__penalty=elasticnet, score=0.7070334133284105, total=   1.4s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9691825059974165, total=   1.4s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9647536445838716, total=   1.4s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9625392138770991, total=   1.4s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9660453958294888, total=   1.4s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9616165344159439, total=   1.4s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9675216829673371, total=   1.4s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.965485418973791, total=   1.4s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.9664082687338501, total=   1.4s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.96012553073657, total=   1.3s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l1, score=0.966402067565073, total=   1.3s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9680752906440303, total=   1.2s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9636464292304854, total=   1.2s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9647536445838716, total=   1.2s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9658608599372578, total=   1.1s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9643845727994095, total=   1.1s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9629082856615612, total=   1.1s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.965485418973791, total=   1.1s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9658545588778147, total=   1.1s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.9590179065903637, total=   1.2s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=l2, score=0.958094886468525, total=   1.1s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.9675216829673371, total=   1.3s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.9642000369071785, total=   1.4s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet, score=0.9643845727994095, total=   1.4s\n",
      "[CV] clf__alpha=0.001, clf__class_weight=None, clf__loss=hinge, clf__penalty=elasticnet \n"
     ]
    }
   ],
   "source": [
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_lr, gs_lr_l2, gs_sgd, \n",
    "         gs_dt, gs_rf, gs_rf_scl, gs_gb, \n",
    "         gs_svm, gs_knn, gs_knn_scl]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0: 'Logistic Regression w/ L1', 1: 'LogisticRegression w/ L2', 2: 'SGDClassifier', 3: 'DecisionTreeClassifier',\n",
    "             4: 'Random Forest', 5: 'Random Forest w/ Scaling', 6: 'GradientBoostingClassifier',\n",
    "            7:'SVC', 8: 'KNeighborsClassifier', 9:'KNeighborsClassifier w/ Scaling'}\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_f1_micro = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "\tprint('\\nEstimator: %s' % grid_dict[idx])\n",
    "\t# Fit grid search\n",
    "\tgs.fit(X_train, y_train)\n",
    "    \n",
    "\t# Best params\n",
    "\tprint('Best params: %s' % gs.best_params_)\n",
    "    \n",
    "\t# Best training data f1\n",
    "\tprint('Best training f1: %.3f' % gs.best_score_)\n",
    "    \n",
    "\t# Predict on test data with best params\n",
    "\ty_pred = gs.predict(X_test)\n",
    "    \n",
    "\t# Test data accuracy of model with best params\n",
    "\tprint('Test set f1 score for best params: %.3f ' % f1_score(y_test, y_pred))\n",
    "    \n",
    "\t# Track best (highest test f1) model\n",
    "\tif f1_score(y_test, y_pred) > best_f1_micro:\n",
    "\t\tbest_f1_micro = f1_score(y_test, y_pred)\n",
    "\t\tbest_gs = gs\n",
    "\t\tbest_clf = idx\n",
    "print('\\nClassifier with best test set f1: %s' % grid_dict[best_clf])\n",
    "\n",
    "# Save best grid search pipeline to file\n",
    "dump_file = 'best_model_no_feat_sel_extr_occ_15.pkl'\n",
    "joblib.dump(best_gs, dump_file, compress=1)\n",
    "print('\\nSaved %s grid search pipeline to file: %s' % (grid_dict[best_clf], dump_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pipe_lr_pca = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('pca', PCA(n_components=2)),\n",
    "\t\t\t('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_sgd_pca = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('pca', PCA(n_components=2)),\n",
    "\t\t\t('clf', SGDClassifier(random_state=42))])\n",
    "\n",
    "pipe_rf_pca = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('pca', PCA(n_components=2)),\n",
    "\t\t\t('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "\n",
    "pipe_svm_pca = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('pca', PCA(n_components=2)),\n",
    "\t\t\t('clf', SVC(random_state=42))])\n",
    "\n",
    "------------------\n",
    "\n",
    "gs_lr_pca = GridSearchCV(estimator=pipe_lr_pca,\n",
    "\t\t\tparam_grid=grid_params_lr,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10,\n",
    "            verbose=verbose)\n",
    "\n",
    "gs_sgd_pca = GridSearchCV(estimator=pipe_sgd_pca,\n",
    "\t\t\tparam_grid=grid_params_sgd,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10,\n",
    "            verbose=verbose)\n",
    "\n",
    "gs_rf_pca = GridSearchCV(estimator=pipe_rf_pca,\n",
    "\t\t\tparam_grid=grid_params_rf,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10, \n",
    "\t\t\tn_jobs=jobs,\n",
    "            verbose=verbose)\n",
    "\n",
    "gs_svm_pca = GridSearchCV(estimator=pipe_svm_pca,\n",
    "\t\t\tparam_grid=grid_params_svm,\n",
    "\t\t\tscoring='f1_micro',\n",
    "\t\t\tcv=10,\n",
    "\t\t\tn_jobs=jobs,\n",
    "            verbose=verbose)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda upgrade matplotlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
